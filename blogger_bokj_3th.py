from urllib.parse import urlparse, parse_qs
import re, json, requests, random, os, textwrap, glob, sys, traceback, pickle
from bs4 import BeautifulSoup
from PIL import Image, ImageDraw, ImageFont
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import gspread
from google.oauth2.service_account import Credentials
from openai import OpenAI
from google.oauth2.credentials import Credentials as UserCredentials
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow

# ================================
# ì¶œë ¥ í•œê¸€ ê¹¨ì§ ë°©ì§€
# ================================
sys.stdout.reconfigure(encoding="utf-8")

# ================================
# ë‹¨ê³„ë³„ ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜ (Pì—´, í•œ ì¤„ ìœ ì§€)
# ================================
def log_step(msg: str):
    """ë‹¨ê³„ë³„ ë¡œê·¸ë¥¼ êµ¬ê¸€ì‹œíŠ¸ Pì—´(16)ì— ëˆ„ì  ê¸°ë¡. ì¤„ë°”ê¿ˆ ëŒ€ì‹  ' | ' ì‚¬ìš©."""
    try:
        tr = globals().get("target_row", None)
        if tr:
            prev = ws.cell(tr, 16).value or ""
            sep = " | " if prev else ""
            ws.update_cell(tr, 16, f"{prev}{sep}{msg}")
    except Exception as e:
        print("âš ï¸ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨:", e)

# ================================
# OpenAI í‚¤ ë¡œë“œ (ì„ íƒ)
# ================================
OPENAI_API_KEY = ""
if os.path.exists("openai.json"):
    with open("openai.json", "r", encoding="utf-8") as f:
        data = json.load(f)
        OPENAI_API_KEY = data.get("api_key", "").strip()
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ================================
# Google Sheets ì¸ì¦
# ================================
try:
    SERVICE_ACCOUNT_FILE = "sheetapi.json"
    SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    gc = gspread.authorize(creds)
    SHEET_ID = os.getenv("SHEET_ID", "1V6ZV_b2NMlqjIobJqV5BBSr9o7_bF8WNjSIwMzQekRs")
    ws = gc.open_by_key(SHEET_ID).sheet1
    log_step("1ë‹¨ê³„: Google Sheets ì¸ì¦ ì„±ê³µ")
except Exception as e:
    print("âŒ Google Sheets ì¸ì¦ ì‹¤íŒ¨:", e)
    raise

# ================================
# ê²½ë¡œ ë° ë¦¬ì†ŒìŠ¤ ì„¤ì •
# ================================
ASSETS_BG_DIR = "assets/backgrounds"
ASSETS_FONT_TTF = "assets/fonts/KimNamyun.ttf"
THUMB_DIR = "thumbnails"

# ================================
# ë¸”ë¡œê·¸ ID ë¡œí…Œì´ì…˜ (3ê°œ)
# ================================
BLOG_IDS = [
    "1271002762142343021",
    "4265887538424434999",
    "6159101125292617147",
]

# ================================
# Google Sheetì—ì„œ ì²˜ë¦¬í•  URL ì°¾ê¸° (Eì—´=URL, Gì—´='ì™„' ì²´í¬)
# ================================
target_row, my_url = None, None
rows = ws.get_all_values()
for i, row in enumerate(rows[1:], start=2):
    url_cell = row[4] if len(row) > 4 else ""   # Eì—´
    status_cell = row[6] if len(row) > 6 else ""  # Gì—´
    if url_cell and (not status_cell or status_cell.strip() != "ì™„"):
        my_url, target_row = url_cell, i
        break
if not my_url:
    log_step("2ë‹¨ê³„: ì²˜ë¦¬í•  URL ì—†ìŒ (ëª¨ë“  í–‰ ì™„ë£Œ)")
    sys.exit(0)
log_step(f"2ë‹¨ê³„: URL ì¶”ì¶œ ì„±ê³µ ({my_url})")

# ================================
# ë¡œí…Œì´ì…˜ ì¸ë±ìŠ¤ ì½ê¸° (O1)
# ================================
def read_rotation_index():
    try:
        val = (ws.acell("O1").value or "").strip()
        idx = int(val)
        if idx < -1 or idx >= len(BLOG_IDS):
            return -1
        return idx
    except:
        return -1

last_index = read_rotation_index()
next_index = (last_index + 1) % len(BLOG_IDS)
BLOG_ID = BLOG_IDS[next_index]
log_step(f"íšŒì „ ì¸ë±ìŠ¤: last={last_index} -> next={next_index} (BLOG_ID={BLOG_ID})")

# ================================
# ì¸ë„¤ì¼ ìƒì„± (ëœë¤ ë°°ê²½)
# ================================
def pick_random_background() -> str:
    files = []
    for ext in ("*.png", "*.jpg", "*.jpeg"):
        files.extend(glob.glob(os.path.join(ASSETS_BG_DIR, ext)))
    return random.choice(files) if files else ""

def make_thumb(save_path: str, var_title: str):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    bg_path = pick_random_background()

    # ë°°ê²½ ë¶ˆëŸ¬ì˜¤ê¸° (ì—†ìœ¼ë©´ í°ìƒ‰ ìº”ë²„ìŠ¤)
    if bg_path and os.path.exists(bg_path):
        bg = Image.open(bg_path).convert("RGBA").resize((500, 500))
    else:
        bg = Image.new("RGBA", (500, 500), (255, 255, 255, 255))

    try:
        font = ImageFont.truetype(ASSETS_FONT_TTF, 48)
    except:
        font = ImageFont.load_default()

    canvas = Image.new("RGBA", (500, 500), (255, 255, 255, 0))
    canvas.paste(bg, (0, 0))

    # ê²€ì€ ë°˜íˆ¬ëª… ë°•ìŠ¤
    rectangle = Image.new("RGBA", (500, 250), (0, 0, 0, 200))
    canvas.paste(rectangle, (0, 125), rectangle)

    draw = ImageDraw.Draw(canvas)

    # ê¸€ì ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    var_title_wrap = textwrap.wrap(var_title, width=12)

    # ì¤„ ê°„ê²©: í°íŠ¸ í¬ê¸° + ì—¬ìœ  (10px)
    line_height = font.getsize("ê°€")[1] + 10  

    total_text_height = len(var_title_wrap) * line_height
    var_y_point = 500 / 2 - total_text_height / 2

    for line in var_title_wrap:
        draw.text((250, var_y_point), line, "#FFEECB", anchor="mm", font=font)
        var_y_point += line_height

    # ìµœì¢… í¬ê¸° ì¡°ì •
    canvas = canvas.resize((400, 400))
    canvas.save(save_path, "PNG")

# ================================
# Google Drive ì¸ì¦ (OAuth: 2nd.json + drive_token_2nd.pickle)
# ================================
def get_drive_service():
    creds = None
    if os.path.exists("drive_token_2nd.pickle"):
        with open("drive_token_2nd.pickle", "rb") as token:
            creds = pickle.load(token)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            # ì•¡ì…˜ í™˜ê²½ì—ì„œëŠ” í† í°ì„ ì‚¬ì „ ë³µì›í•´ì•¼ í•¨ (ë¡œì»¬ì„œë²„ ë¶ˆê°€)
            raise RuntimeError("drive_token_2nd.pickleì´ ì—†ê±°ë‚˜ ë§Œë£Œë¨. GitHub Secretsì—ì„œ ë³µì› í•„ìš”.")
        with open("drive_token_2nd.pickle", "wb") as token:
            pickle.dump(creds, token)

    return build("drive", "v3", credentials=creds)

# ================================
# Google Drive ì—…ë¡œë“œ (blogger í´ë”)
# ================================
def upload_to_drive(file_path, file_name):
    try:
        drive_service = get_drive_service()
        # blogger í´ë” í™•ì¸/ìƒì„±
        query = "mimeType='application/vnd.google-apps.folder' and name='blogger' and trashed=false"
        results = drive_service.files().list(q=query, fields="files(id, name)").execute()
        items = results.get("files", [])
        if items:
            folder_id = items[0]["id"]
        else:
            folder_metadata = {"name": "blogger", "mimeType": "application/vnd.google-apps.folder"}
            folder = drive_service.files().create(body=folder_metadata, fields="id").execute()
            folder_id = folder.get("id")

        file_metadata = {"name": file_name, "parents": [folder_id]}
        media = MediaFileUpload(file_path, mimetype="image/png", resumable=True)
        file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()

        # anyone ì½ê¸° ê¶Œí•œ
        drive_service.permissions().create(
            fileId=file["id"],
            body={"role": "reader", "type": "anyone", "allowFileDiscovery": False}
        ).execute()

        file_id = file["id"]
        log_step("3ë‹¨ê³„: êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì„±ê³µ")
        return f"https://lh3.googleusercontent.com/d/{file_id}"
    except Exception as e:
        log_step(f"3ë‹¨ê³„: êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

# ================================
# Blogger ì¸ì¦ (refresh_token JSON)
# ================================
def get_blogger_service():
    try:
        if not os.path.exists("blogger_token.json"):
            raise FileNotFoundError("blogger_token.json íŒŒì¼ ì—†ìŒ")
        with open("blogger_token.json", "r", encoding="utf-8") as f:
            data = json.load(f)
        creds = UserCredentials.from_authorized_user_info(data, ["https://www.googleapis.com/auth/blogger"])
        return build("blogger", "v3", credentials=creds)
    except Exception as e:
        log_step(f"ë¸”ë¡œê±° ì¸ì¦ ì‹¤íŒ¨: {e}")
        raise

blog_handler = get_blogger_service()
log_step("5ë‹¨ê³„: Blogger ì¸ì¦ ì„±ê³µ")

# ================================
# ë³µì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# ================================
def fetch_welfare_info(wlfareInfoId):
    url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={wlfareInfoId}&wlfareInfoReldBztpCd=01"
    resp = requests.get(url)
    resp.encoding = "utf-8"
    html = resp.text
    outer_match = re.search(r'initParameter\((\{.*?\})\);', html, re.S)
    if not outer_match:
        raise ValueError("initParameter JSONì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return json.loads(json.loads(outer_match.group(1))["initValue"]["dmWlfareInfo"])

def clean_html(raw_html):
    return BeautifulSoup(raw_html, "html.parser").get_text(separator="\n", strip=True)

# ================================
# ChatGPT APIë¡œ ë³¸ë¬¸ ê°€ê³µ (ìš”ì•½ + 3~4ë¬¸ë‹¨, <p size18> ê°•ì œ)
# ================================
def process_with_gpt(section_title: str, raw_text: str, keyword: str) -> str:
    if not client:
        return f"<p data-ke-size='size18'><b>{keyword} {section_title}</b></p><p data-ke-size='size18'>{clean_html(raw_text)}</p>"

    system_msg = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë¸”ë¡œê·¸ ê¸€ì„ ì“°ëŠ” ì¹´í”¼ë¼ì´í„°ì•¼. "
        "ì£¼ì œëŠ” ì •ë¶€ ë³µì§€ì„œë¹„ìŠ¤ì´ê³ , ì£¼ì–´ì§„ ì›ë¬¸ì„ "
        "1) ë¨¼ì € <b>íƒœê·¸ë¡œ êµµê²Œ ìš”ì•½(í•œë‘ ë¬¸ì¥)</b>, "
        "2) ê·¸ ì•„ë˜ì— ì¹œì ˆí•˜ê³  ìì„¸í•œ ì„¤ëª…ì„ ë¶™ì´ëŠ” í˜•íƒœë¡œ ê°€ê³µí•´. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ 3~4ê°œì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‘ì„±í•˜ë˜, "
        "ê° ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” <p data-ke-size=\"size18\"> íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ê³  "
        "ë¹ˆ ì¤„(ì¤„ë°”ê¿ˆ)ìœ¼ë¡œ êµ¬ë¶„í•´. "
        "ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€, ë°˜ë“œì‹œ <p data-ke-size=\"size18\"> íƒœê·¸ ì‚¬ìš©."
    )
    user_msg = f"[ì„¹ì…˜ ì œëª©] {keyword} {section_title}\n[ì›ë¬¸]\n{raw_text}"

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.7,
            max_tokens=800,
        )
        log_step(f"4ë‹¨ê³„: GPT ë³€í™˜ ì„±ê³µ ({section_title})")
        return resp.choices[0].message.content.strip()
    except Exception as e:
        log_step(f"4ë‹¨ê³„: GPT ë³€í™˜ ì‹¤íŒ¨ ({section_title}): {e}")
        return f"<p data-ke-size='size18'>{clean_html(raw_text)}</p>"

# ================================
# ì„œë¡ /ë§ˆë¬´ë¦¬ 7ë¬¸ì¥ ëœë¤
# ================================
_syn = {
    "ë„ì›€": ["ë„ì›€", "ì§€ì›", "í˜œíƒ", "ë³´íƒ¬", "ìœ ìµ"],
    "ì•ˆë‚´": ["ì•ˆë‚´", "ì†Œê°œ", "ì •ë¦¬", "ê°€ì´ë“œ", "ì„¤ëª…"],
    "ì¤‘ìš”í•œ": ["ì¤‘ìš”í•œ", "í•µì‹¬ì ì¸", "í•„ìˆ˜ì ì¸", "ê¼­ ì•Œì•„ì•¼ í• "],
    "ì‰½ê²Œ": ["ì‰½ê²Œ", "ê°„ë‹¨íˆ", "ìˆ˜ì›”í•˜ê²Œ", "í¸ë¦¬í•˜ê²Œ"],
    "ì •ë³´": ["ì •ë³´", "ë‚´ìš©", "ìë£Œ", "ì†Œì‹", "ë°ì´í„°"],
    "ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤": ["ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤", "ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤", "ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"],
}
def _c(w): return random.choice(_syn.get(w, [w]))

def make_intro(keyword):
    parts = [
        f"{keyword}ì€ ë§ì€ ë¶„ë“¤ì´ ê´€ì‹¬ì„ ê°–ëŠ” {_c('ì¤‘ìš”í•œ')} ì œë„ì…ë‹ˆë‹¤.",
        "ì •ë¶€ëŠ” ì´ë¥¼ í†µí•´ ìƒí™œì˜ ì–´ë ¤ì›€ì„ ëœì–´ì£¼ê³ ì í•©ë‹ˆë‹¤.",
        f"ì œë„ë¥¼ ì˜ ì´í•´í•˜ë©´ í˜œíƒì„ ë”ìš± {_c('ì‰½ê²Œ')} ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        f"ì˜¤ëŠ˜ì€ {keyword}ì˜ ê°œìš”ë¶€í„° ì‹ ì²­ ë°©ë²•ê¹Œì§€ ê¼¼ê¼¼íˆ {_c('ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤')}.",
        "ì‹¤ì œ ìƒí™œì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì‚¬ë¡€ë¥¼ í†µí•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ìœ¼ì‹œë©´ ì œë„ë¥¼ ì´í•´í•˜ëŠ” ë° í° ë³´íƒ¬ì´ ë˜ì‹¤ ê²ë‹ˆë‹¤.",
        "ì—¬ëŸ¬ë¶„ê»˜ ê¼­ í•„ìš”í•œ ì§€ì‹ê³¼ í˜œíƒì„ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
    ]
    return " ".join(parts)

def make_last(keyword):
    parts = [
        f"ì˜¤ëŠ˜ì€ {keyword} ì œë„ë¥¼ {_c('ì•ˆë‚´')}í–ˆìŠµë‹ˆë‹¤.",
        f"ì´ {_c('ì •ë³´')}ë¥¼ ì°¸ê³ í•˜ì…”ì„œ ì‹¤ì œ ì‹ ì²­ì— {_c('ë„ì›€')}ì´ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ê¼­ í•„ìš”í•œ ë¶„ë“¤ì´ í˜œíƒì„ ëˆ„ë¦¬ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ì•ìœ¼ë¡œë„ ë‹¤ì–‘í•œ ë³µì§€ ì •ë³´ë¥¼ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëŒ“ê¸€ê³¼ ì˜ê²¬ë„ ë‚¨ê²¨ì£¼ì‹œë©´ í° í˜ì´ ë©ë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ë‹¤ìŒ ê¸€ë„ ê¸°ëŒ€í•´ ì£¼ì„¸ìš”.",
        "ì—¬ëŸ¬ë¶„ì˜ ìƒí™œì´ ë” ë‚˜ì•„ì§€ê¸¸ ë°”ë¼ë©° ê¸€ì„ ë§ˆì¹©ë‹ˆë‹¤.",
    ]
    return " ".join(parts)

# ================================
# ì¶”ì²œê¸€ ë°•ìŠ¤ (feedparser í•„ìš”)
# ================================
def get_related_posts(blog_id, count=4):
    try:
        import feedparser
    except ImportError:
        log_step("ì¶”ì²œê¸€ ë°•ìŠ¤ ìƒëµ(feedparser ë¯¸ì„¤ì¹˜)")
        return ""
    rss_url = f"https://www.blogger.com/feeds/{blog_id}/posts/default?alt=rss"
    feed = feedparser.parse(rss_url)
    if not feed.entries:
        return ""
    entries = random.sample(feed.entries, min(count, len(feed.entries)))
    html_box = """
<div style="background:#efede9;border-radius:8px;border:2px dashed #a7a297;
            box-shadow:#efede9 0 0 0 10px;color:#565656;font-weight:bold;
            margin:2em 10px;padding:2em;">
  <p data-ke-size="size16"
     style="border-bottom:1px solid #555;color:#555;font-size:16px;
            margin-bottom:15px;padding-bottom:5px;">â™¡â™¥ ê°™ì´ ë³´ë©´ ì¢‹ì€ê¸€</p>
"""
    for entry in entries:
        html_box += f'<a href="{entry.link}" style="color:#555;font-weight:normal;">â— {entry.title}</a><br>\n'
    html_box += "</div>\n"
    return html_box

# ================================
# ë³¸ë¬¸ ìƒì„± + í¬ìŠ¤íŒ…
# ================================
try:
    parsed = urlparse(my_url)
    params = parse_qs(parsed.query)
    wlfareInfoId = params.get("wlfareInfoId", [""])[0]
    data = fetch_welfare_info(wlfareInfoId)

    keyword = clean_html(data.get("wlfareInfoNm", "ë³µì§€ ì„œë¹„ìŠ¤"))
    title = f"2025 {keyword} ì§€ì› ìê²© ì‹ ì²­ë°©ë²•"
    safe_keyword = re.sub(r'[\\/:*?"<>|.]', "_", keyword)

    # ì¸ë„¤ì¼ ìƒì„±/ì—…ë¡œë“œ
    os.makedirs(THUMB_DIR, exist_ok=True)
    thumb_path = os.path.join(THUMB_DIR, f"{safe_keyword}.png")
    make_thumb(thumb_path, title)
    log_step("6ë‹¨ê³„: ì¸ë„¤ì¼ ìƒì„± ì„±ê³µ")
    img_url = upload_to_drive(thumb_path, f"{safe_keyword}.png")

    # ì„œë¡ /ë§ˆë¬´ë¦¬
    intro = make_intro(keyword)
    last = make_last(keyword)

    # HTML ì¡°ë¦½
    html = f"""
<div id="jm">&nbsp;</div>
<p data-ke-size="size18">{intro}</p><br />
<p style="text-align:center;">
  <img src="{img_url}" alt="{keyword} ì¸ë„¤ì¼" style="max-width:100%; height:auto; border-radius:10px;">
</p>
<span><!--more--></span><br />
"""

    fields = {
        "ê°œìš”": "wlfareInfoOutlCn",
        "ì§€ì›ëŒ€ìƒ": "wlfareSprtTrgtCn",
        "ì„œë¹„ìŠ¤ë‚´ìš©": "wlfareSprtBnftCn",
        "ì‹ ì²­ë°©ë²•": "aplyMtdDc",
        "ì¶”ê°€ì •ë³´": "etct"
    }
    for title_k, key in fields.items():
        value = data.get(key, "")
        if value and value.strip() not in ["", "ì •ë³´ ì—†ìŒ"]:
            processed = process_with_gpt(title_k, clean_html(value), keyword)
            html += f"<br /><h2 data-ke-size='size26'>{keyword} {title_k}</h2><br />{processed}<br /><br />"

    # CTA + ë§ˆë¬´ë¦¬ + ì¶”ì²œê¸€
    related_box = get_related_posts(BLOG_ID)
    html += f"""
<div style="margin:40px 0 20px 0;">
  <p style="text-align:center;" data-ke-size="size18">
    <a class="myButton" href="{my_url}" target="_blank">ğŸ‘‰ {keyword} ìì„¸íˆ ë³´ê¸°</a>
  </p><br />
  <p data-ke-size="size18">{last}</p>
</div>
{related_box}
"""

    # ê²Œì‹œ
    post_body = {
        "content": html,
        "title": title,
        "labels": ["ë³µì§€", "ì •ë¶€ì§€ì›"],
        "blog": {"id": BLOG_ID}
    }
    res = blog_handler.posts().insert(blogId=BLOG_ID, body=post_body, isDraft=False, fetchImages=True).execute()

    # === í¬ìŠ¤íŒ… ì™„ë£Œ í›„ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ===
    ws.update_cell(target_row, 7, "ì™„")          # Gì—´: "ì™„"
    ws.update_cell(target_row, 15, res["url"])   # Oì—´: í¬ìŠ¤íŒ… URLë§Œ
    final_html = res.get("content", "")
    soup = BeautifulSoup(final_html, "html.parser")
    img_tag = soup.find("img")
    final_url = img_tag["src"] if img_tag else ""
    log_step(f"7ë‹¨ê³„: ì—…ë¡œë“œ ì„±ê³µ â†’ IMG={final_url}")
    ws.update_acell("O1", str(next_index))       # O1: ì‚¬ìš©í•œ ì¸ë±ìŠ¤ ì €ì¥

    print(f"[ì™„ë£Œ] ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…: {res['url']}")
except Exception as e:
    tb = traceback.format_exc().replace("\n", " | ")
    log_step(f"7ë‹¨ê³„: ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e} | {tb}")
    raise

