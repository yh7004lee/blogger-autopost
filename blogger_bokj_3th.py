import re
import json
import requests
import random
import os
import urllib.parse
import sys, traceback
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials as UserCredentials
from google.oauth2.service_account import Credentials
from googleapiclient.http import MediaFileUpload
import gspread
from openai import OpenAI

# ================================
# ì¶œë ¥ í•œê¸€ ê¹¨ì§ ë°©ì§€
# ================================
sys.stdout.reconfigure(encoding="utf-8")

# ================================
# OpenAI API í‚¤ ë¡œë“œ
# ================================
OPENAI_API_KEY = ""
if os.path.exists("openai.json"):
    try:
        with open("openai.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            OPENAI_API_KEY = data.get("api_key", "").strip()
    except Exception as e:
        print("[ERROR] openai.json íŒŒì‹± ì‹¤íŒ¨:", e)

if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

if not OPENAI_API_KEY:
    print("[ERROR] OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

client = OpenAI(api_key=OPENAI_API_KEY)

# ================================
# Google Sheets ì¸ì¦
# ================================
SERVICE_ACCOUNT_FILE = "sheetapi.json"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

try:
    creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    gc = gspread.authorize(creds)
except Exception as e:
    print(f"[ERROR] Google Sheets ì¸ì¦ ì‹¤íŒ¨: {e}")
    sys.exit(1)

SHEET_ID = os.getenv("SHEET_ID", "1V6ZV_b2NMlqjIobJqV5BBSr9o7_bF8WNjSIwMzQekRs")
ws = gc.open_by_key(SHEET_ID).sheet1

# ================================
# ë¸”ë¡œê·¸ ID ë¡œí…Œì´ì…˜ (O1 ì…€)
# ================================
BLOG_IDS = ["1271002762142343021", "4265887538424434999", "6159101125292617147"]

try:
    last_index = int(ws.acell("O1").value or "-1")
except:
    last_index = -1

next_index = (last_index + 1) % len(BLOG_IDS)
BLOG_ID = BLOG_IDS[next_index]
ws.update_acell("O1", str(next_index))
print(f"ğŸ‘‰ ì´ë²ˆ í¬ìŠ¤íŒ… ë¸”ë¡œê·¸ ID: {BLOG_ID}")

# ================================
# URL ê°€ì ¸ì˜¤ê¸° (Eì—´ URL, Gì—´ ìƒíƒœ)
# ================================
target_row, my_url = None, None
rows = ws.get_all_values()

for i, row in enumerate(rows[1:], start=2):  # 2í–‰ë¶€í„°
    url_cell = row[4] if len(row) > 4 else ""   # Eì—´ (URL)
    status_cell = row[6] if len(row) > 6 else "" # Gì—´ ("ì™„")
    if url_cell and (not status_cell or status_cell.strip() != "ì™„"):
        my_url, target_row = url_cell, i
        break

if not my_url:
    print("ğŸ”” ì²˜ë¦¬í•  ìƒˆë¡œìš´ URLì´ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  í–‰ ì™„ë£Œë¨)")
    sys.exit(0)

print("ğŸ‘‰ ì´ë²ˆì— ì²˜ë¦¬í•  URL:", my_url)

parsed = urllib.parse.urlparse(my_url)
params = urllib.parse.parse_qs(parsed.query)
wlfareInfoId = params.get("wlfareInfoId", [""])[0]
print("wlfareInfoId =", wlfareInfoId)

# ================================
# ë³µì§€ ì„œë¹„ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# ================================
def fetch_welfare_info(wlfareInfoId):
    url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={wlfareInfoId}&wlfareInfoReldBztpCd=01"
    resp = requests.get(url)
    resp.encoding = "utf-8"
    html = resp.text
    outer_match = re.search(r'initParameter\((\{.*?\})\);', html, re.S)
    if not outer_match:
        raise ValueError("initParameter JSONì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    outer_data = json.loads(outer_match.group(1))
    inner_str = outer_data["initValue"]["dmWlfareInfo"]
    return json.loads(inner_str)

def clean_html(raw_html):
    return BeautifulSoup(raw_html, "html.parser").get_text(separator="\n", strip=True)

# ================================
# GPT ë³€í™˜
# ================================
def process_with_gpt(section_title: str, raw_text: str, keyword: str) -> str:
    system_msg = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë¸”ë¡œê·¸ ê¸€ì„ ì“°ëŠ” ì¹´í”¼ë¼ì´í„°ì•¼. "
        "ì£¼ì œëŠ” ì •ë¶€ ë³µì§€ì„œë¹„ìŠ¤ì´ê³ , ì£¼ì–´ì§„ ì›ë¬¸ì„ "
        "1) ë¨¼ì € <b>íƒœê·¸ë¡œ êµµê²Œ ìš”ì•½(í•œë‘ ë¬¸ì¥)</b>, "
        "2) ê·¸ ì•„ë˜ì— ì¹œì ˆí•˜ê³  ìì„¸í•œ ì„¤ëª…ì„ ë¶™ì´ëŠ” í˜•íƒœë¡œ ê°€ê³µí•´. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ <p data-ke-size=\"size18\"> íƒœê·¸ë¥¼ ì‚¬ìš©í•´ ë¬¸ë‹¨ì„ ë‚˜ëˆ„ê³  "
        "ë§ˆí¬ë‹¤ìš´ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ."
    )
    user_msg = f"[ì„¹ì…˜ ì œëª©] {keyword} {section_title}\n[ì›ë¬¸]\n{raw_text}"

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.7,
            max_tokens=900,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print("[WARN] GPT ì²˜ë¦¬ ì‹¤íŒ¨:", e)
        return f"<p data-ke-size='size18'>{clean_html(raw_text)}</p>"

# ================================
# Blogger ì¸ì¦ (refresh_token JSON ë°©ì‹)
# ================================
def get_blogger_service():
    if not os.path.exists("blogger_token.json"):
        raise FileNotFoundError("[ERROR] blogger_token.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    with open("blogger_token.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    creds = UserCredentials.from_authorized_user_info(
        data,
        ["https://www.googleapis.com/auth/blogger"]
    )
    return build("blogger", "v3", credentials=creds)

blog_handler = get_blogger_service()

# ================================
# ë³¸ë¬¸ ìƒì„± ë° ì—…ë¡œë“œ
# ================================
data = fetch_welfare_info(wlfareInfoId)
keyword = clean_html(data.get("wlfareInfoNm", "ë³µì§€ ì„œë¹„ìŠ¤"))
title = f"2025 {keyword} ì§€ì› ëŒ€ìƒ ì‹ ì²­ë°©ë²• ì´ì •ë¦¬"
print("ìë™ ìƒì„±ëœ ì œëª©:", title)

fields = {
    "ê°œìš”": "wlfareInfoOutlCn",
    "ì§€ì›ëŒ€ìƒ": "wlfareSprtTrgtCn",
    "ì„œë¹„ìŠ¤ë‚´ìš©": "wlfareSprtBnftCn",
    "ì‹ ì²­ë°©ë²•": "aplyMtdDc",
    "ì¶”ê°€ì •ë³´": "etct"
}

html = f"""
<div id="jm">&nbsp;</div>
<p data-ke-size="size18">{keyword}ì€ ë§ì€ ë¶„ë“¤ì´ ê´€ì‹¬ì„ ê°–ëŠ” ì¤‘ìš”í•œ ì œë„ì…ë‹ˆë‹¤.</p><br />
<span><!--more--></span><br />
"""

for title_k, key in fields.items():
    value = data.get(key, "")
    if not value or value.strip() in ["", "ì •ë³´ ì—†ìŒ"]:
        continue
    processed_text = process_with_gpt(title_k, clean_html(value), keyword)
    html += f"<br /><h2 data-ke-size='size26'>{keyword} {title_k}</h2><br />{processed_text}<br /><br />"

html += f"""
<div class="custom-button">
  <a href="{my_url}" target="_blank">ğŸ‘‰ {keyword} ìì„¸íˆ ì•Œì•„ë³´ê¸°</a>
</div>
"""

data_post = {
    'content': html,
    'title': title,
    'labels': ["ë³µì§€", "ì •ë¶€ì§€ì›", "ë³µì§€ì„œë¹„ìŠ¤"],
    'blog': {'id': BLOG_ID},
}

try:
    posts = blog_handler.posts()
    res = posts.insert(blogId=BLOG_ID, body=data_post, isDraft=False, fetchImages=True).execute()
    print(f"[ì™„ë£Œ] ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…: {res['url']}")
except Exception as e:
    print("[ERROR] ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
    traceback.print_exc()
    sys.exit(1)

# ================================
# âœ… êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (Gì—´ "ì™„")
# ================================


# âœ… êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (Gì—´ "ì™„")
ws.update_cell(target_row, 7, "ì™„")  # Gì—´
ws.update_cell(target_row, 15, res['url']) # Oì—´ (15ë²ˆì§¸ ì—´)
print("âœ… êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ (Gì—´ 'ì™„' + Oì—´ í¬ìŠ¤íŒ… URL ê¸°ë¡)")


print(title)


