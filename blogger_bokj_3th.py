from urllib.parse import urlparse, parse_qs
import re, json, requests, random, os, textwrap, glob, sys, traceback
from bs4 import BeautifulSoup
from PIL import Image, ImageDraw, ImageFont
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import gspread
from google.oauth2.service_account import Credentials
from openai import OpenAI
from google.oauth2.credentials import Credentials as UserCredentials
import feedparser

# ================================
# ì¶œë ¥ í•œê¸€ ê¹¨ì§ ë°©ì§€
# ================================
sys.stdout.reconfigure(encoding="utf-8")

# ================================
# ë‹¨ê³„ë³„ ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜ (Pì—´ ì‚¬ìš©)
# ================================
def log_step(msg):
    try:
        if target_row:
            prev = ws.cell(target_row, 16).value or ""  # Pì—´ (16ë²ˆì§¸)
            new_log = prev + f"{msg}\n"
            ws.update_cell(target_row, 16, new_log)
    except Exception as e:
        print("âš ï¸ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨:", e)

# ================================
# OpenAI API í‚¤ ë¡œë“œ
# ================================
OPENAI_API_KEY = ""
if os.path.exists("openai.json"):
    with open("openai.json", "r", encoding="utf-8") as f:
        data = json.load(f)
        OPENAI_API_KEY = data.get("api_key", "").strip()
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ================================
# Google Sheets ì¸ì¦
# ================================
SERVICE_ACCOUNT_FILE = "sheetapi.json"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
gc = gspread.authorize(creds)
SHEET_ID = os.getenv("SHEET_ID", "1V6ZV_b2NMlqjIobJqV5BBSr9o7_bF8WNjSIwMzQekRs")
ws = gc.open_by_key(SHEET_ID).sheet1
log_step("1ë‹¨ê³„: Google Sheets ì¸ì¦ ì„±ê³µ")

# ================================
# ê²½ë¡œ ë° ë¦¬ì†ŒìŠ¤ ì„¤ì •
# ================================
ASSETS_BG_DIR = "assets/backgrounds"
ASSETS_FONT_TTF = "assets/fonts/KimNamyun.ttf"
THUMB_DIR = "thumbnails"
DRIVE_FOLDER_ID = "1Z6WF4Lt-Ou8S70SKkE5M4tTHxrXJHxKU"

# ================================
# Google Sheetì—ì„œ URL ê°€ì ¸ì˜¤ê¸°
# ================================
target_row, my_url = None, None
rows = ws.get_all_values()
for i, row in enumerate(rows[1:], start=2):
    url_cell = row[4] if len(row) > 4 else ""
    status_cell = row[6] if len(row) > 6 else ""  # Gì—´
    if url_cell and (not status_cell or status_cell.strip() != "ì™„"):
        my_url, target_row = url_cell, i
        break
if not my_url:
    log_step("2ë‹¨ê³„: ì²˜ë¦¬í•  URL ì—†ìŒ (ëª¨ë“  í–‰ ì™„ë£Œ)")
    sys.exit(0)
log_step(f"2ë‹¨ê³„: URL ì¶”ì¶œ ì„±ê³µ ({my_url})")

# ================================
# ì¸ë„¤ì¼ ìƒì„± (ëœë¤ ë°°ê²½)
# ================================
def pick_random_background():
    files = []
    for ext in ("*.png", "*.jpg", "*.jpeg"):
        files.extend(glob.glob(os.path.join(ASSETS_BG_DIR, ext)))
    return random.choice(files) if files else ""

def make_thumb(save_path, var_title):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    bg_path = pick_random_background()
    bg = Image.open(bg_path).convert("RGBA").resize((500, 500)) if (bg_path and os.path.exists(bg_path)) else Image.new("RGBA", (500, 500), (255, 255, 255, 255))

    try:
        font = ImageFont.truetype(ASSETS_FONT_TTF, 48)
    except:
        font = ImageFont.load_default()

    canvas = Image.new("RGBA", (500, 500), (255, 255, 255, 0))
    canvas.paste(bg, (0, 0))
    rectangle = Image.new("RGBA", (500, 250), (0, 0, 0, 200))
    canvas.paste(rectangle, (0, 125), rectangle)

    draw = ImageDraw.Draw(canvas)
    var_title_wrap = textwrap.wrap(var_title, width=12)
    var_y_point = 500/2 - (len(var_title_wrap) * 30) / 2
    for line in var_title_wrap:
        draw.text((250, var_y_point), line, "#FFEECB", anchor="mm", font=font)
        var_y_point += 40

    canvas = canvas.resize((400, 400))
    canvas.save(save_path, "PNG")

# ================================
# Google Drive ì—…ë¡œë“œ
# ================================
def get_drive_service():
    creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=["https://www.googleapis.com/auth/drive.file"])
    return build("drive", "v3", credentials=creds)

def upload_to_drive(file_path, file_name):
    drive_service = get_drive_service()
    file_metadata = {"name": file_name, "parents": [DRIVE_FOLDER_ID]}
    media = MediaFileUpload(file_path, mimetype="image/png", resumable=True)
    file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    drive_service.permissions().create(fileId=file["id"], body={"role": "reader", "type": "anyone"}).execute()
    return f"https://lh3.googleusercontent.com/d/{file['id']}"

# ================================
# Blogger ì¸ì¦ (refresh_token JSON)
# ================================
def get_blogger_service():
    if not os.path.exists("blogger_token.json"):
        raise FileNotFoundError("blogger_token.json íŒŒì¼ ì—†ìŒ")
    with open("blogger_token.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    creds = UserCredentials.from_authorized_user_info(data, ["https://www.googleapis.com/auth/blogger"])
    return build("blogger", "v3", credentials=creds)

blog_handler = get_blogger_service()
log_step("3ë‹¨ê³„: Blogger ì¸ì¦ ì„±ê³µ")

# ================================
# ë³µì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# ================================
def fetch_welfare_info(wlfareInfoId):
    url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={wlfareInfoId}&wlfareInfoReldBztpCd=01"
    resp = requests.get(url)
    resp.encoding = "utf-8"
    html = resp.text
    outer_match = re.search(r'initParameter\((\{.*?\})\);', html, re.S)
    if not outer_match:
        raise ValueError("initParameter JSONì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return json.loads(json.loads(outer_match.group(1))["initValue"]["dmWlfareInfo"])

def clean_html(raw_html):
    return BeautifulSoup(raw_html, "html.parser").get_text(separator="\n", strip=True)

# ================================
# GPT API ë³€í™˜
# ================================
def process_with_gpt(section_title, raw_text, keyword):
    if not client:
        return f"<p data-ke-size='size18'><b>{keyword} {section_title}</b></p><p data-ke-size='size18'>{clean_html(raw_text)}</p>"
    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ ë¸”ë¡œê·¸ ê¸€ì„ ì“°ëŠ” ì¹´í”¼ë¼ì´í„°ì•¼. ì¹œì ˆí•˜ê³  SEO ì¹œí™”ì ì¸ HTML ê¸€ë§Œ ì¶œë ¥í•´."},
                {"role": "user", "content": f"[ì„¹ì…˜ ì œëª©] {keyword} {section_title}\n[ì›ë¬¸]\n{raw_text}"}
            ],
            temperature=0.7,
            max_tokens=800,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        log_step(f"GPT ë³€í™˜ ì‹¤íŒ¨ ({section_title}): {e}")
        return f"<p data-ke-size='size18'>{clean_html(raw_text)}</p>"

# ================================
# 7ë¬¸ë‹¨ ì„œë¡  / 7ë¬¸ë‹¨ ë§ˆë¬´ë¦¬
# ================================
def choice(word, synonyms):
    return random.choice(synonyms.get(word, [word]))

synonyms = {
    "ë„ì›€": ["ë„ì›€", "ì§€ì›", "í˜œíƒ", "ë³´íƒ¬", "ì´ìµ", "ìœ ìµ", "ì•ˆì •ë§"],
    "ì•ˆë‚´": ["ì•ˆë‚´", "ì†Œê°œ", "ì •ë¦¬", "ê°€ì´ë“œ", "ì„¤ëª…", "í’€ì´"],
    "ì¤‘ìš”í•œ": ["ì¤‘ìš”í•œ", "í•µì‹¬ì ì¸", "í•„ìˆ˜ì ì¸", "ê¼­ ì•Œì•„ì•¼ í• "],
    "ì‰½ê²Œ": ["ì‰½ê²Œ", "ê°„ë‹¨íˆ", "ìˆ˜ì›”í•˜ê²Œ", "í¸ë¦¬í•˜ê²Œ"],
    "ì •ë³´": ["ì •ë³´", "ë‚´ìš©", "ìë£Œ", "ì†Œì‹", "ë°ì´í„°"],
    "ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤": ["ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤", "ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤", "ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"],
}

def make_intro(keyword):
    parts = [
        f"{keyword}ì€ ë§ì€ ë¶„ë“¤ì´ ê´€ì‹¬ì„ ê°–ëŠ” {choice('ì¤‘ìš”í•œ', synonyms)} ì œë„ì…ë‹ˆë‹¤.",
        "ì •ë¶€ëŠ” ì´ë¥¼ í†µí•´ ìƒí™œì˜ ì–´ë ¤ì›€ì„ ëœì–´ì£¼ê³ ì í•©ë‹ˆë‹¤.",
        f"ì œë„ë¥¼ ì˜ ì´í•´í•˜ë©´ í˜œíƒì„ ë”ìš± {choice('ì‰½ê²Œ', synonyms)} ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        f"ì˜¤ëŠ˜ì€ {keyword}ì˜ ê°œìš”ë¶€í„° ì‹ ì²­ ë°©ë²•ê¹Œì§€ ê¼¼ê¼¼íˆ {choice('ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤', synonyms)}.",
        "ì‹¤ì œ ìƒí™œì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì‚¬ë¡€ë¥¼ í†µí•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ìœ¼ì‹œë©´ ì œë„ë¥¼ ì´í•´í•˜ëŠ” ë° í° ë³´íƒ¬ì´ ë˜ì‹¤ ê²ë‹ˆë‹¤.",
        "ì—¬ëŸ¬ë¶„ê»˜ ê¼­ í•„ìš”í•œ ì§€ì‹ê³¼ í˜œíƒì„ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
    ]
    return " ".join(random.sample(parts, 7))

def make_last(keyword):
    parts = [
        f"ì˜¤ëŠ˜ì€ {keyword} ì œë„ë¥¼ {choice('ì•ˆë‚´', synonyms)}í–ˆìŠµë‹ˆë‹¤.",
        f"ì´ {choice('ì •ë³´', synonyms)}ë¥¼ ì°¸ê³ í•˜ì…”ì„œ ì‹¤ì œ ì‹ ì²­ì— {choice('ë„ì›€', synonyms)}ì´ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ì•ìœ¼ë¡œë„ ë‹¤ì–‘í•œ ë³µì§€ ì •ë³´ë¥¼ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëŒ“ê¸€ê³¼ ì˜ê²¬ë„ ë‚¨ê²¨ì£¼ì‹œë©´ í° í˜ì´ ë©ë‹ˆë‹¤.",
        "ì•ìœ¼ë¡œ ë‹¤ë£° ì£¼ì œì— ëŒ€í•œ ì˜ê²¬ë„ ê¸°ë‹¤ë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ë‹¤ìŒ ê¸€ë„ ê¸°ëŒ€í•´ ì£¼ì„¸ìš”.",
        "ì—¬ëŸ¬ë¶„ì˜ ìƒí™œì´ ë” ë‚˜ì•„ì§€ê¸¸ ë°”ë¼ë©° ê¸€ì„ ë§ˆì¹©ë‹ˆë‹¤.",
    ]
    return " ".join(random.sample(parts, 7))

# ================================
# ì¶”ì²œê¸€ ë°•ìŠ¤
# ================================
def get_related_posts(blog_id, count=4):
    rss_url = f"https://www.blogger.com/feeds/{blog_id}/posts/default?alt=rss"
    feed = feedparser.parse(rss_url)
    if not feed.entries:
        return ""
    entries = random.sample(feed.entries, min(count, len(feed.entries)))
    html_box = """
<div style="background: rgb(239, 237, 233); border-radius: 8px; border: 2px dashed rgb(167, 162, 151); 
            box-shadow: rgb(239, 237, 233) 0px 0px 0px 10px; color: #565656; font-weight: bold; 
            margin: 2em 10px; padding: 2em;">
  <p data-ke-size="size16" 
     style="border-bottom: 1px solid rgb(85, 85, 85); color: #555555; font-size: 16px; 
            margin-bottom: 15px; padding-bottom: 5px;">â™¡â™¥ ê°™ì´ ë³´ë©´ ì¢‹ì€ê¸€</p>
"""
    for entry in entries:
        html_box += f'<a href="{entry.link}" style="color: #555555; font-weight: normal;">â— {entry.title}</a><br>\n'
    html_box += "</div>\n"
    return html_box

# ================================
# ë³¸ë¬¸ ìƒì„± + í¬ìŠ¤íŒ…
# ================================
try:
    parsed = urlparse(my_url)
    params = parse_qs(parsed.query)
    wlfareInfoId = params.get("wlfareInfoId", [""])[0]
    data = fetch_welfare_info(wlfareInfoId)

    keyword = clean_html(data.get("wlfareInfoNm", "ë³µì§€ ì„œë¹„ìŠ¤"))
    title = f"2025 {keyword} ì§€ì› ìê²© ì‹ ì²­ë°©ë²•"
    safe_keyword = re.sub(r'[\\/:*?"<>|.]', "_", keyword)

    os.makedirs(THUMB_DIR, exist_ok=True)
    thumb_path = os.path.join(THUMB_DIR, f"{safe_keyword}.png")
    make_thumb(thumb_path, title)
    img_url = upload_to_drive(thumb_path, f"{safe_keyword}.png")
    log_step("4ë‹¨ê³„: ì¸ë„¤ì¼ ìƒì„± + ì—…ë¡œë“œ ì„±ê³µ")

    intro = make_intro(keyword)
    last = make_last(keyword)

    html = f"""
    <div id="jm">&nbsp;</div>
    <p data-ke-size="size18">{intro}</p><br />
    <p style="text-align:center;">
      <img src="{img_url}" alt="{keyword} ì¸ë„¤ì¼" style="max-width:100%; height:auto; border-radius:10px;">
    </p>
    <span><!--more--></span><br />
    """

    fields = {"ê°œìš”":"wlfareInfoOutlCn","ì§€ì›ëŒ€ìƒ":"wlfareSprtTrgtCn","ì„œë¹„ìŠ¤ë‚´ìš©":"wlfareSprtBnftCn","ì‹ ì²­ë°©ë²•":"aplyMtdDc","ì¶”ê°€ì •ë³´":"etct"}
    for title_k, key in fields.items():
        value = data.get(key, "")
        if value and value.strip() not in ["", "ì •ë³´ ì—†ìŒ"]:
            processed = process_with_gpt(title_k, clean_html(value), keyword)
            html += f"<br /><h2 data-ke-size='size26'>{keyword} {title_k}</h2><br />{processed}<br /><br />"

    related_box = get_related_posts(os.getenv("BLOG_ID", "5711594645656469839"))

    html += f"""
<div style="margin:40px 0px 20px 0px;">
<p style="text-align: center;" data-ke-size="size18">
<a class="myButton" href="{my_url}" target="_blank">ğŸ‘‰ {keyword} ë°”ë¡œê°€ê¸°</a></p><br />
<p data-ke-size="size18">{last}</p>
</div>
{related_box}
"""

    BLOG_ID = os.getenv("BLOG_ID", "5711594645656469839")
    post_body = {"content": html, "title": title, "labels": ["ë³µì§€","ì •ë¶€ì§€ì›"], "blog": {"id": BLOG_ID}}
    res = blog_handler.posts().insert(blogId=BLOG_ID, body=post_body, isDraft=False, fetchImages=True).execute()

    ws.update_cell(target_row, 7, "ì™„")  # Gì—´ ê¸°ë¡
    log_step("5ë‹¨ê³„: ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì„±ê³µ")

    print(f"[ì™„ë£Œ] ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…: {res['url']}")
except Exception as e:
    tb = traceback.format_exc()
    log_step(f"ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\n{tb}")
    raise
