from urllib.parse import urlparse, parse_qs
import re, json, requests, random, os, textwrap, glob, sys, traceback, pickle, time
from bs4 import BeautifulSoup
from PIL import Image, ImageDraw, ImageFont
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import gspread
from google.oauth2.service_account import Credentials
from openai import OpenAI
from google.oauth2.credentials import Credentials as UserCredentials
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow

# ================================
# ì¶œë ¥ í•œê¸€ ê¹¨ì§ ë°©ì§€
# ================================
sys.stdout.reconfigure(encoding="utf-8")

# ================================
# ë¡œê·¸ ê¸°ë¡ (Pì—´ì— ëˆ„ì , í•œ ì¤„ì”©ë§Œ)
# ================================
def log_step(msg: str):
    try:
        tr = globals().get("target_row", None)
        if tr:
            prev = ws.cell(tr, 16).value or ""
            ws.update_cell(tr, 16, f"{prev} | {msg}" if prev else msg)
    except Exception as e:
        print("âš ï¸ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨:", e)

# ================================
# OpenAI API Key ë¡œë“œ
# ================================
OPENAI_API_KEY = ""
if os.path.exists("openai.json"):
    with open("openai.json", "r", encoding="utf-8") as f:
        data = json.load(f)
        OPENAI_API_KEY = data.get("api_key", "").strip()
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ================================
# Google Sheets ì¸ì¦
# ================================
try:
    SERVICE_ACCOUNT_FILE = "sheetapi.json"
    SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    gc = gspread.authorize(creds)
    SHEET_ID = os.getenv("SHEET_ID", "1V6ZV_b2NMlqjIobJqV5BBSr9o7_bF8WNjSIwMzQekRs")
    ws = gc.open_by_key(SHEET_ID).sheet1
    log_step("1ë‹¨ê³„: Google Sheets ì¸ì¦ ì„±ê³µ")
except Exception as e:
    log_step(f"1ë‹¨ê³„: Google Sheets ì¸ì¦ ì‹¤íŒ¨: {e}")
    raise

ASSETS_BG_DIR = "assets/backgrounds"
ASSETS_FONT_TTF = "assets/fonts/KimNamyun.ttf"
THUMB_DIR = "thumbnails"

# ================================
# URL ê°€ì ¸ì˜¤ê¸° (Eì—´=URL, Gì—´â‰ ì™„)
# ================================
target_row, my_url = None, None
rows = ws.get_all_values()
for i, row in enumerate(rows[1:], start=2):
    url_cell = row[4] if len(row) > 4 else ""
    status_cell = row[6] if len(row) > 6 else ""
    if url_cell and (not status_cell or status_cell.strip() != "ì™„"):
        my_url, target_row = url_cell, i
        break
if not my_url:
    log_step("2ë‹¨ê³„: ì²˜ë¦¬í•  URL ì—†ìŒ")
    sys.exit(0)
log_step(f"2ë‹¨ê³„: URL ì¶”ì¶œ ì„±ê³µ ({my_url})")

# ================================
# ì¸ë„¤ì¼ ìƒì„±
# ================================
def pick_random_background() -> str:
    files = []
    for ext in ("*.png", "*.jpg", "*.jpeg"):
        files.extend(glob.glob(os.path.join(ASSETS_BG_DIR, ext)))
    return random.choice(files) if files else ""

def make_thumb(save_path: str, var_title: str):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    bg_path = pick_random_background()
    if bg_path and os.path.exists(bg_path):
        bg = Image.open(bg_path).convert("RGBA").resize((500, 500))
    else:
        bg = Image.new("RGBA", (500, 500), (255, 255, 255, 255))
    try:
        font = ImageFont.truetype(ASSETS_FONT_TTF, 48)
    except:
        font = ImageFont.load_default()
    canvas = Image.new("RGBA", (500, 500), (255, 255, 255, 0))
    canvas.paste(bg, (0, 0))
    rectangle = Image.new("RGBA", (500, 250), (0, 0, 0, 200))
    canvas.paste(rectangle, (0, 125), rectangle)
    draw = ImageDraw.Draw(canvas)
    var_title_wrap = textwrap.wrap(var_title, width=12)
    bbox = font.getbbox("ê°€")
    line_height = (bbox[3] - bbox[1]) + 12
    total_text_height = len(var_title_wrap) * line_height
    var_y_point = 500 / 2 - total_text_height / 2
    for line in var_title_wrap:
        text_bbox = draw.textbbox((0, 0), line, font=font)
        text_width = text_bbox[2] - text_bbox[0]
        x = (500 - text_width) / 2
        draw.text((x, var_y_point), line, "#FFEECB", font=font)
        var_y_point += line_height
    canvas = canvas.resize((400, 400))
    canvas.save(save_path, "PNG")

# ================================
# Google Drive ì¸ì¦ (OAuth pickle)
# ================================
def get_drive_service():
    creds = None
    if os.path.exists("drive_token_2nd.pickle"):
        with open("drive_token_2nd.pickle", "rb") as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                "2nd.json", ["https://www.googleapis.com/auth/drive.file"]
            )
            creds = flow.run_local_server(port=0)
        with open("drive_token_2nd.pickle", "wb") as token:
            pickle.dump(creds, token)
    return build("drive", "v3", credentials=creds)

def upload_to_drive(file_path, file_name):
    drive_service = get_drive_service()
    query = "mimeType='application/vnd.google-apps.folder' and name='blogger' and trashed=false"
    results = drive_service.files().list(q=query, fields="files(id, name)").execute()
    items = results.get("files", [])
    if items:
        folder_id = items[0]["id"]
    else:
        folder_metadata = {"name": "blogger", "mimeType": "application/vnd.google-apps.folder"}
        folder = drive_service.files().create(body=folder_metadata, fields="id").execute()
        folder_id = folder.get("id")
    file_metadata = {"name": file_name, "parents": [folder_id]}
    media = MediaFileUpload(file_path, mimetype="image/png", resumable=True)
    file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    drive_service.permissions().create(fileId=file["id"], body={"role": "reader", "type": "anyone"}).execute()
    return f"https://lh3.googleusercontent.com/d/{file['id']}"

# ================================
# Blogger ì¸ì¦
# ================================
def get_blogger_service():
    if not os.path.exists("blogger_token.json"):
        raise FileNotFoundError("blogger_token.json ì—†ìŒ")
    with open("blogger_token.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    creds = UserCredentials.from_authorized_user_info(data, ["https://www.googleapis.com/auth/blogger"])
    return build("blogger", "v3", credentials=creds)

blog_handler = get_blogger_service()
log_step("5ë‹¨ê³„: Blogger ì¸ì¦ ì„±ê³µ")

# ================================
# ë³µì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# ================================
def fetch_welfare_info(wlfareInfoId):
    url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={wlfareInfoId}&wlfareInfoReldBztpCd=01"
    resp = requests.get(url)
    resp.encoding = "utf-8"
    html = resp.text
    outer_match = re.search(r'initParameter\((\{.*?\})\);', html, re.S)
    if not outer_match:
        raise ValueError("initParameter JSONì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return json.loads(json.loads(outer_match.group(1))["initValue"]["dmWlfareInfo"])

def clean_html(raw_html):
    return BeautifulSoup(raw_html, "html.parser").get_text(separator="\n", strip=True)

# ================================
# ChatGPT API ê°€ê³µ
# ================================
def process_with_gpt(section_title, raw_text, keyword):
    if not client:
        return f"<p data-ke-size='size18'>{clean_html(raw_text)}</p>"
    system_msg = (
        "ë„ˆëŠ” í•œêµ­ì–´ ë¸”ë¡œê·¸ ê¸€ì„ ì“°ëŠ” ì¹´í”¼ë¼ì´í„°ì•¼. "
        "ì£¼ì œëŠ” ì •ë¶€ ë³µì§€ì„œë¹„ìŠ¤ì´ê³ , ì£¼ì–´ì§„ ì›ë¬¸ì„ "
        "1) ë¨¼ì € <b>íƒœê·¸ë¡œ êµµê²Œ ìš”ì•½(í•œë‘ ë¬¸ì¥)</b>, "
        "2) ê·¸ ì•„ë˜ì— ì¹œì ˆí•˜ê³  ìì„¸í•œ ì„¤ëª…ì„ ë¶™ì´ëŠ” í˜•íƒœë¡œ ê°€ê³µí•´. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ 3~4ê°œì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‘ì„±í•˜ë˜, "
        "ê° ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” <p data-ke-size=\"size18\"> íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ê³  "
        "ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€."
    )
    user_msg = f"[ì„¹ì…˜ ì œëª©] {keyword} {section_title}\n[ì›ë¬¸]\n{raw_text}"
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
        temperature=0.7,
        max_tokens=800,
    )
    return resp.choices[0].message.content.strip()

# ================================
# ì„œë¡ Â·ë§ˆë¬´ë¦¬ ëœë¤
# ================================
synonyms = {
    "ë„ì›€": ["ë„ì›€","ì§€ì›","í˜œíƒ","ë³´íƒ¬","ìœ ìµ"],
    "ì•ˆë‚´": ["ì•ˆë‚´","ì†Œê°œ","ì •ë¦¬","ê°€ì´ë“œ","ì„¤ëª…"],
    "ì¤‘ìš”í•œ": ["ì¤‘ìš”í•œ","í•µì‹¬ì ì¸","í•„ìˆ˜ì ì¸","ê¼­ ì•Œì•„ì•¼ í• "],
    "ì‰½ê²Œ": ["ì‰½ê²Œ","ê°„ë‹¨íˆ","ìˆ˜ì›”í•˜ê²Œ","í¸ë¦¬í•˜ê²Œ"],
    "ì •ë³´": ["ì •ë³´","ë‚´ìš©","ìë£Œ","ì†Œì‹"],
    "ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤": ["ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤","ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤","ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"]
}
def choice(word): return random.choice(synonyms.get(word,[word]))
def make_intro(keyword):
    return " ".join([
        f"{keyword}ì€ ë§ì€ ë¶„ë“¤ì´ ê´€ì‹¬ì„ ê°–ëŠ” {choice('ì¤‘ìš”í•œ')} ì œë„ì…ë‹ˆë‹¤.",
        "ì •ë¶€ëŠ” ì´ë¥¼ í†µí•´ ìƒí™œì˜ ì–´ë ¤ì›€ì„ ëœì–´ì£¼ê³ ì í•©ë‹ˆë‹¤.",
        f"ì œë„ë¥¼ ì˜ ì´í•´í•˜ë©´ í˜œíƒì„ ë”ìš± {choice('ì‰½ê²Œ')} ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        f"ì˜¤ëŠ˜ì€ {keyword}ì˜ ê°œìš”ë¶€í„° ì‹ ì²­ ë°©ë²•ê¹Œì§€ ê¼¼ê¼¼íˆ {choice('ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤')}.",
        "ì‹¤ì œ ìƒí™œì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì‚¬ë¡€ë¥¼ í†µí•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ìœ¼ì‹œë©´ ì œë„ë¥¼ ì´í•´í•˜ëŠ” ë° í° ë³´íƒ¬ì´ ë˜ì‹¤ ê²ë‹ˆë‹¤."
    ])
def make_last(keyword):
    return " ".join([
        f"ì˜¤ëŠ˜ì€ {keyword} ì œë„ë¥¼ {choice('ì•ˆë‚´')}í–ˆìŠµë‹ˆë‹¤.",
        f"ì´ {choice('ì •ë³´')}ë¥¼ ì°¸ê³ í•˜ì…”ì„œ ì‹¤ì œ ì‹ ì²­ì— {choice('ë„ì›€')}ì´ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ì•ìœ¼ë¡œë„ ë‹¤ì–‘í•œ ë³µì§€ ì •ë³´ë¥¼ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
    ])

# ================================
# ì¶”ì²œê¸€ ë°•ìŠ¤
# ================================
def get_related_posts(blog_id, count=4):
    import feedparser
    rss_url = f"https://www.blogger.com/feeds/{blog_id}/posts/default?alt=rss"
    feed = feedparser.parse(rss_url)
    if not feed.entries: return ""
    entries = random.sample(feed.entries, min(count, len(feed.entries)))
    html_box = """
<div style="background:#efede9;border-radius:8px;border:2px dashed #a7a297;
            box-shadow:#efede9 0 0 0 10px;color:#565656;font-weight:bold;
            margin:2em 10px;padding:2em;">
  <p data-ke-size="size16"
     style="border-bottom:1px solid #555;color:#555;font-size:16px;
            margin-bottom:15px;padding-bottom:5px;">â™¡â™¥ ê°™ì´ ë³´ë©´ ì¢‹ì€ê¸€</p>
"""
    for entry in entries:
        html_box += f'<a href="{entry.link}" style="color:#555;font-weight:normal;">â— {entry.title}</a><br>\n'
    html_box += "</div>\n"
    return html_box

# ================================
# ë³¸ë¬¸ ìƒì„± + í¬ìŠ¤íŒ…
# ================================
try:
    parsed = urlparse(my_url)
    params = parse_qs(parsed.query)
    wlfareInfoId = params.get("wlfareInfoId", [""])[0]
    data = fetch_welfare_info(wlfareInfoId)
    keyword = clean_html(data.get("wlfareInfoNm", "ë³µì§€ ì„œë¹„ìŠ¤"))
    title = f"2025 {keyword} ì§€ì› ìê²© ì‹ ì²­ë°©ë²•"
    safe_keyword = re.sub(r'[\\/:*?"<>|.]', "_", keyword)
    os.makedirs(THUMB_DIR, exist_ok=True)
    thumb_path = os.path.join(THUMB_DIR, f"{safe_keyword}.png")
    make_thumb(thumb_path, title)
    log_step("6ë‹¨ê³„: ì¸ë„¤ì¼ ìƒì„± ì„±ê³µ")
    img_url = upload_to_drive(thumb_path, f"{safe_keyword}.png")
    intro = make_intro(keyword)
    last = make_last(keyword)
    fields = {
        "ê°œìš”": "wlfareInfoOutlCn",
        "ì§€ì›ëŒ€ìƒ": "wlfareSprtTrgtCn",
        "ì„œë¹„ìŠ¤ë‚´ìš©": "wlfareSprtBnftCn",
        "ì‹ ì²­ë°©ë²•": "aplyMtdDc",
        "ì¶”ê°€ì •ë³´": "etct"
    }
    html = f"""
<div id="jm">&nbsp;</div>
<p data-ke-size="size18">{intro}</p><br />
<p style="text-align:center;">
  <img src="{img_url}" alt="{keyword} ì¸ë„¤ì¼" style="max-width:100%; height:auto; border-radius:10px;">
</p>
<span><!--more--></span><br />
"""
    for title_k, key in fields.items():
        value = data.get(key, "")
        if value and value.strip() not in ["", "ì •ë³´ ì—†ìŒ"]:
            processed = process_with_gpt(title_k, clean_html(value), keyword)
            html += f"<br /><h2 data-ke-size='size26'>{keyword} {title_k}</h2><br />{processed}<br /><br />"
    BLOG_ID = os.getenv("BLOG_ID", "5711594645656469839")
    related_box = get_related_posts(BLOG_ID)
    html += f"""
<div style="margin:40px 0 20px 0;">
  <p style="text-align:center;" data-ke-size="size18">
    <a class="myButton" href="{my_url}" target="_blank">ğŸ‘‰ {keyword} ìì„¸íˆ ë³´ê¸°</a>
  </p><br />
  <p data-ke-size="size18">{last}</p>
</div>
{related_box}
"""
    labels = ["ë³µì§€", "ì •ë¶€ì§€ì›"]
    for word in ["ì²­ë…„", "ì¥ì• ì¸", "ì†Œìƒê³µì¸", "ì—¬ì„±", "ì„ì‚°ë¶€", "ì§€ì›ê¸ˆ"]:
        if word in title:
            labels.append(word)
    post_body = {"content": html, "title": title, "labels": labels, "blog": {"id": BLOG_ID}}
    res = blog_handler.posts().insert(blogId=BLOG_ID, body=post_body, isDraft=False, fetchImages=True).execute()
    ws.update_cell(target_row, 7, "ì™„")
    ws.update_cell(target_row, 15, res["url"])
    log_step(f"7ë‹¨ê³„: ì—…ë¡œë“œ ì„±ê³µ ({res['url']})")
    print(f"[ì™„ë£Œ] ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…: {res['url']}")
except Exception as e:
    tb = traceback.format_exc().replace("\n", " | ")
    log_step(f"7ë‹¨ê³„: ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e} | {tb}")
    raise
