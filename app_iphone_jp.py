#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
sys.stdout.reconfigure(encoding="utf-8")
import urllib.parse
# =============== Imports ===============
import os, re, json, random, requests, traceback, pickle, glob, textwrap, time
from bs4 import BeautifulSoup

# Google Sheets / Drive / Blogger
import gspread
from google.oauth2.service_account import Credentials as SA_Credentials
from google.oauth2.credentials import Credentials as UserCredentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# OpenAI (ì„ íƒ)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# PIL (ì¸ë„¤ì¼ ìƒì„±ìš©)
from PIL import Image, ImageDraw, ImageFont

# =============== í™˜ê²½ ë³€ìˆ˜ ë° ê¸°ë³¸ ì„¤ì • ===============
SHEET_ID = os.getenv("SHEET_ID", "1SeQogbinIrDTMKjWhGgWPEQq8xv6ARv5n3I-2BsMrSc")
DRIVE_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID", "YOUR_DRIVE_FOLDER_ID")

# ë¸”ë¡œê·¸ ID / URL (ì¼ë³¸ ë²„ì „ìœ¼ë¡œ ê³ ì •)
BLOG_ID = "7573892357971022707"
BLOG_URL = "https://jpapp.appsos.kr/"

# Google Custom Search (ì„ íƒ ì‚¬í•­: ë¯¸ì‚¬ìš© ì‹œ ì•±ìŠ¤í† ì–´ ì§ì ‘ íŒŒì‹±)
GCS_API_KEY = os.getenv("GCS_API_KEY", "").strip()
GCS_CX = os.getenv("GCS_CX", "").strip()

# OpenAI API Key ë¡œë“œ (openai.json ë˜ëŠ” í™˜ê²½ë³€ìˆ˜) â€” ì„ íƒ ì‚¬ìš©
OPENAI_API_KEY = ""
if os.path.exists("openai.json"):
    try:
        with open("openai.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            OPENAI_API_KEY = data.get("api_key", "").strip()
    except Exception:
        OPENAI_API_KEY = ""
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
client = OpenAI(api_key=OPENAI_API_KEY) if (OpenAI and OPENAI_API_KEY) else None

# =============== Google Sheets ì¸ì¦ (sheet4 ì‚¬ìš©) ===============
def get_sheet4():
    # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
    service_account_file = "sheetapi.json"
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = SA_Credentials.from_service_account_file(service_account_file, scopes=scopes)
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SHEET_ID)
    try:
        ws4 = sh.worksheet("sheet4")   # ì‹œíŠ¸ ì´ë¦„ì´ 'sheet4'ì¸ ê²½ìš°
    except Exception:
        ws4 = sh.get_worksheet(3)      # 0ë¶€í„° ì‹œì‘ â†’ ë„¤ ë²ˆì§¸ íƒ­
    return ws4

ws4 = get_sheet4()

# =============== Google Drive ì¸ì¦ ===============
def get_drive_service():
    # GitHub Actions ë“±ì—ì„œ ì‚¬ìš©ì í† í°ì„ pickle ë¡œ ì €ì¥í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë¥¼ ê°€ì •
    token_path = "drive_token_2nd.pickle"
    if not os.path.exists(token_path):
        raise RuntimeError("drive_token_2nd.pickle ì—†ìŒ â€” Drive API ì‚¬ìš©ì í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    with open(token_path, "rb") as f:
        creds = pickle.load(f)
    if not creds.valid and creds.expired and creds.refresh_token:
        creds.refresh(Request())
        with open(token_path, "wb") as f:
            pickle.dump(creds, f)
    return build("drive", "v3", credentials=creds)

# =============== Blogger ì¸ì¦ ===============
def get_blogger_service():
    if not os.path.exists("blogger_token.json"):
        raise RuntimeError("blogger_token.json ì—†ìŒ â€” Blogger ì‚¬ìš©ì ì¸ì¦ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    with open("blogger_token.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    creds = UserCredentials.from_authorized_user_info(
        data, ["https://www.googleapis.com/auth/blogger"]
    )
    return build("blogger", "v3", credentials=creds)

blog_handler = get_blogger_service()

# =============== ì¸ë„¤ì¼ ë¡œê·¸ ê¸°ë¡ (Hì—´ ì‚¬ìš©) ===============
def log_thumb_step(ws, row_idx, message):
    try:
        prev = ws.cell(row_idx, 8).value or ""   # Hì—´
        new_val = prev + (";" if prev else "") + message
        ws.update_cell(row_idx, 8, new_val)
    except Exception as e:
        print("[ë¡œê¹… ì‹¤íŒ¨]", e)

# =============== ë°°ê²½ ì´ë¯¸ì§€ ëœë¤ ì„ íƒ ===============
def pick_random_background() -> str:
    files = []
    for ext in ("*.png", "*.jpg", "*.jpeg"):
        files.extend(glob.glob(os.path.join("assets", "backgrounds", ext)))
    return random.choice(files) if files else ""

# =============== ì¸ë„¤ì¼ ìƒì„± ===============
def make_thumb(save_path: str, var_title: str):
    try:
        os.makedirs(os.path.dirname(save_path) or ".", exist_ok=True)

        # ëœë¤ ë°°ê²½ ì„ íƒ
        bg_path = pick_random_background()
        if bg_path and os.path.exists(bg_path):
            bg = Image.open(bg_path).convert("RGBA").resize((500, 500))
        else:
            bg = Image.new("RGBA", (500, 500), (255, 255, 255, 255))

        # í°íŠ¸ ì„¤ì • (ì¼ë³¸ì–´ ì§€ì› í°íŠ¸ë¡œ êµì²´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        try:
            font = ImageFont.truetype(os.path.join("assets", "fonts", "NotoSansJP-VariableFont_wght.ttf"), 48)
        except Exception:
            font = ImageFont.load_default()

        # ìº”ë²„ìŠ¤ ìƒì„±
        canvas = Image.new("RGBA", (500, 500), (255, 255, 255, 0))
        canvas.paste(bg, (0, 0))

        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤
        rectangle = Image.new("RGBA", (500, 250), (0, 0, 0, 200))
        canvas.paste(rectangle, (0, 125), rectangle)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw = ImageDraw.Draw(canvas)

        var_title_wrap = textwrap.wrap(var_title, width=12)
        bbox = font.getbbox("ê°€")  # ê¸°ì¤€ ê¸€ì
        line_height = (bbox[3] - bbox[1]) + 12
        total_text_height = len(var_title_wrap) * line_height
        y = 500 / 2 - total_text_height / 2

        for line in var_title_wrap:
            text_bbox = draw.textbbox((0, 0), line, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            x = (500 - text_width) / 2
            draw.text((x, y), line, "#FFEECB", font=font)
            y += line_height

        # í¬ê¸° ì¡°ì • í›„ ì €ì¥
        canvas = canvas.resize((400, 400))
        canvas.save(save_path, "PNG")
        return True
    except Exception as e:
        print(f"ì—ëŸ¬: ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        return False

# =============== Google Drive ì—…ë¡œë“œ â†’ ê³µê°œ URL ë°˜í™˜ ===============
def upload_to_drive(file_path, file_name):
    try:
        drive_service = get_drive_service()
        folder_id = DRIVE_FOLDER_ID

        if not folder_id or folder_id == "YOUR_DRIVE_FOLDER_ID":
            # ê¸°ë³¸ blogger í´ë” ì‚¬ìš©
            query = "mimeType='application/vnd.google-apps.folder' and name='blogger' and trashed=false"
            results = drive_service.files().list(q=query, fields="files(id, name)").execute()
            items = results.get("files", [])
            if items:
                folder_id = items[0]["id"]
            else:
                folder_metadata = {"name": "blogger", "mimeType": "application/vnd.google-apps.folder"}
                folder = drive_service.files().create(body=folder_metadata, fields="id").execute()
                folder_id = folder.get("id")

        file_metadata = {"name": file_name, "parents": [folder_id]}
        media = MediaFileUpload(file_path, mimetype="image/png", resumable=True)
        file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()

        # ê³µê°œ ê¶Œí•œ ë¶€ì—¬
        drive_service.permissions().create(
            fileId=file["id"],
            body={"role": "reader", "type": "anyone", "allowFileDiscovery": False}
        ).execute()

        # âœ… Google CDN(lh3) ì£¼ì†Œ ë°˜í™˜
        return f"https://lh3.googleusercontent.com/d/{file['id']}"
    except Exception as e:
        print(f"ì—ëŸ¬: êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return ""


# =============== ì¸ë„¤ì¼ ìƒì„± + ë¡œê·¸ + ì—…ë¡œë“œ ===============
def make_thumb_with_logging(ws, row_idx, save_path, title):
    try:
        log_thumb_step(ws, row_idx, "ì¸ë„¤ì¼ ì‹œì‘")
        ok = make_thumb(save_path, title)
        if ok:
            log_thumb_step(ws, row_idx, "ì¸ë„¤ì¼ ì™„ë£Œ")
            url = upload_to_drive(save_path, os.path.basename(save_path))
            if url:
                log_thumb_step(ws, row_idx, f"ì—…ë¡œë“œ ì™„ë£Œ â†’ {url}")
                return url
            else:
                log_thumb_step(ws, row_idx, "ì—…ë¡œë“œ ì‹¤íŒ¨")
                return ""
        else:
            log_thumb_step(ws, row_idx, "ì¸ë„¤ì¼ ì‹¤íŒ¨")
            return ""
    except Exception as e:
        log_thumb_step(ws, row_idx, f"ì—ëŸ¬:{e}")
        return ""


# =============== ì œëª©/ë¼ë²¨ ìƒì„± ===============
def make_post_title(keyword: str) -> str:
    # ì¼ë³¸ì–´ ë²„ì „ ì œëª© êµ¬ì„±
    front_choices = ["iPhone iPad", "iPad iPhone"]
    back_choices = ["ã‚¢ãƒ—ãƒª ãŠã™ã™ã‚", "ãŠã™ã™ã‚ ã‚¢ãƒ—ãƒª", "ã‚¢ãƒ—ãƒª AppStore", "AppStore ã‚¢ãƒ—ãƒª"]
    return f"{random.choice(front_choices)} {keyword} {random.choice(back_choices)}"

def make_post_labels(sheet_row: list) -> list:
    # í•­ìƒ "ã‚¢ãƒ—ãƒª" + ì‹œíŠ¸ Bì—´ ë¼ë²¨
    label_val = sheet_row[1].strip() if len(sheet_row) > 1 and sheet_row[1] else ""
    return ["ã‚¢ãƒ—ãƒª", label_val] if label_val else ["ã‚¢ãƒ—ãƒª"]


# =============== OpenAI GPT ì¬ì‘ì„± (ì•± ì„¤ëª…) ===============
def rewrite_app_description(original_html: str, app_name: str, keyword_str: str) -> str:
    compact = BeautifulSoup(original_html or "", 'html.parser').get_text(separator=' ', strip=True)
    if not client:
        if compact:
            return "".join([f"<p data-ke-size='size18'>{line.strip()}</p>" for line in compact.splitlines() if line.strip()]) or f"<p data-ke-size='size18'>{app_name} ç´¹ä»‹</p>"
        return f"<p data-ke-size='size18'>{app_name} ç´¹ä»‹</p>"

    system_msg = (
        "ã‚ãªãŸã¯æ—¥æœ¬èªã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’æ›¸ãã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚"
        "å†…å®¹ã®äº‹å®Ÿã¯ä¿æŒã—ã¤ã¤ã€æ–‡ç« ã‚„æ§‹æˆã‚’å®Œå…¨ã«ãƒªãƒ©ã‚¤ãƒˆã—ã¦ãã ã•ã„ã€‚"
        "äººé–“ãŒæ›¸ã„ãŸã‚ˆã†ã«è‡ªç„¶ã§æ¸©ã‹ã„ãƒˆãƒ¼ãƒ³ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        "Markdownã¯ç¦æ­¢ã€<p data-ke-size='size18'> ã‚¿ã‚°ã®ã¿ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
        "å¿…ãš3ã€œ4ã¤ã®æ®µè½ã«åˆ†ã‘ã¦ã€å„æ®µè½ã¯ <p data-ke-size='size18'> ã‚¿ã‚°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    )
    user_msg = (
        f"[ã‚¢ãƒ—ãƒªå] {app_name}\n"
        f"[ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰] {keyword_str}\n"
        "ä»¥ä¸‹ã®åŸæ–‡ã‚’å‚è€ƒã«ã€ãƒ–ãƒ­ã‚°ç”¨ã®ç´¹ä»‹æ–‡ã‚’æ–°ã—ãæ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚\n\n"
        f"{compact}"
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.7,
            max_tokens=700,
        )
        rewritten = resp.choices[0].message.content.strip()
        if "<p" not in rewritten:
            rewritten = f'<p data-ke-size="size18">{rewritten}</p>'
        return rewritten
    except Exception as e:
        print("[OpenAI ì˜¤ë¥˜]", e)
        if compact:
            return f"<p data-ke-size='size18'>{compact}</p>"
        return f"<p data-ke-size='size18'>{app_name} ç´¹ä»‹</p>"


# =============== ì•±ìŠ¤í† ì–´ ì•± ID ì¶”ì¶œ (iTunes Search API, ì¼ë³¸) ===============
# =============== ì•±ìŠ¤í† ì–´ ì•± ID ì¶”ì¶œ (ì¼ë³¸) ===============
def search_app_store_ids(keyword, limit=20, country="jp"):
    import urllib.parse

    def fetch(term):
        encoded = urllib.parse.quote(term)
        url = f"https://itunes.apple.com/search?term={encoded}&country={country}&entity=software&limit={limit}"
        print("[iTunes API ìš”ì²­]", url)
        try:
            res = requests.get(url, timeout=10)
            if res.status_code != 200:
                print(f"[iTunes API ì‹¤íŒ¨] HTTP {res.status_code}")
                return []
            data = res.json()
            results = data.get("results", [])
            apps = []
            for app in results:
                if "trackId" in app and "trackName" in app:
                    apps.append({"id": str(app["trackId"]), "name": app["trackName"]})
            return apps
        except Exception as e:
            print("[iTunes API ì˜ˆì™¸]", e)
            print(traceback.format_exc())
            return []

    # âœ… 1ì°¨: ì› í‚¤ì›Œë“œ
    apps = fetch(keyword)

    # âœ… 2ì°¨: ë¶€ì¡±í•˜ë©´ "app" ë¶™ì—¬ì„œ
    if len(apps) < 7:
        more = fetch(f"{keyword} app")
        apps.extend(more)

    # âœ… 3ì°¨: ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ "ã‚¢ãƒ—ãƒª" ë¶™ì—¬ì„œ
    if len(apps) < 7:
        more = fetch(f"{keyword} ã‚¢ãƒ—ãƒª")
        apps.extend(more)

    # âœ… trackId ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    seen = set()
    unique_apps = []
    for app in apps:
        if app["id"] not in seen:
            seen.add(app["id"])
            unique_apps.append(app)

    print(f"[iTunes API ìµœì¢… ê²°ê³¼] {[(a['id'], a['name']) for a in unique_apps]}")
    return unique_apps



# =============== ì•± ìƒì„¸ í˜ì´ì§€ ìˆ˜ì§‘ (ì´ë¦„/ì„¤ëª…/ìŠ¤í¬ë¦°ìƒ·, ì¼ë³¸) ===============
def fetch_app_detail(app_id: str, country="jp"):
    import html
    url = f"https://apps.apple.com/{country}/app/id{app_id}"
    name = f"ã‚¢ãƒ—ãƒª {app_id}"
    desc_html, images = "", []

    try:
        resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=20)
        resp.encoding = "utf-8"
        # lxml ë¯¸ì„¤ì¹˜ í™˜ê²½ ëŒ€ë¹„
        try:
            soup = BeautifulSoup(resp.text, "lxml")
        except Exception:
            soup = BeautifulSoup(resp.text, "html.parser")

        # ì•± ì´ë¦„
        h1 = soup.find("h1")
        if h1:
            name = html.unescape(h1.get_text(strip=True))
        else:
            og_title = soup.find("meta", property="og:title")
            if og_title and og_title.get("content"):
                name = html.unescape(og_title["content"])

        # ì•± ì„¤ëª…
        desc_div = soup.find("div", class_=re.compile(r"(section__description|description)"))
        if desc_div:
            ps = desc_div.find_all("p")
            if ps:
                desc_html = "".join(
                    f"<p data-ke-size='size18'>{html.unescape(p.get_text(strip=True))}</p>"
                    for p in ps if p.get_text(strip=True)
                )

        if not desc_html:
            meta_desc = soup.find("meta", attrs={"name": "description"}) or soup.find("meta", property="og:description")
            if meta_desc and meta_desc.get("content"):
                desc_html = f"<p data-ke-size='size18'>{html.unescape(meta_desc['content'].strip())}</p>"

        # ìŠ¤í¬ë¦°ìƒ· ìˆ˜ì§‘
        for s in soup.find_all("source"):
            srcset = s.get("srcset", "")
            if srcset:
                img_url = srcset.split(" ")[0]
                if img_url and img_url.startswith("https"):
                    images.append(img_url)

        if not images:
            for img in soup.find_all("img"):
                src = img.get("src") or ""
                if "mzstatic.com" in src:
                    images.append(src)

        # ì¤‘ë³µ ì œê±° + ìµœëŒ€ 4ê°œ
        images = list(dict.fromkeys(images))[:4]

        return {
            "url": url,
            "name": name,
            "desc_html": desc_html,
            "images": images
        }
    except Exception as e:
        print(f"[ì•± ìƒì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨] id={app_id}, error={e}")
        return {"url": url, "name": name, "desc_html": "", "images": []}

# =============== CSS ë¸”ë¡ (í•œ ë²ˆë§Œ ì¶œë ¥) ===============
def build_css_block() -> str:
    return """
<style>
.img-group {
  display: flex;
  flex-wrap: wrap;
  justify-content: center;
}
.img-wrap {
  flex: 0 0 48%;
  margin: 1%;
}
.img-wrap img {
  width: 100%;
  height: auto;
  border-radius: 10px;
}
@media (max-width: 768px) {
  .img-wrap {
    flex: 0 0 100%;
    margin: 5px 0;
  }
}
</style>
"""

# =============== ì„œë¡  ë¸”ë¡ ===============
def build_intro_block(title: str, keyword: str) -> str:
    intro_groups = [
        [
            f"ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã¯ä»Šã‚„å˜ãªã‚‹é€šä¿¡æ‰‹æ®µã‚’è¶…ãˆã€ç§ãŸã¡ã®ç”Ÿæ´»å…¨èˆ¬ã‚’æ”¯ãˆã‚‹å¿…éœ€å“ã¨ãªã£ã¦ã„ã¾ã™ã€‚",
            f"æ‰‹ã®ã²ã‚‰ã‚µã‚¤ã‚ºã®ãƒ‡ãƒã‚¤ã‚¹ä¸€ã¤ã§ã€{keyword}ã€ã®ã‚ˆã†ãªå¤šå½©ãªæ©Ÿèƒ½ã‚’æ¥½ã—ã‚ã‚‹æ™‚ä»£ã«ãªã‚Šã¾ã—ãŸã€‚",
            f"ç¾ä»£ç¤¾ä¼šã«ãŠã„ã¦ã€{keyword}ã€ã‚¢ãƒ—ãƒªã¯æ¬ ã‹ã›ãªã„ä¾¿åˆ©ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å®šç€ã—ã¦ã„ã¾ã™ã€‚",
            f"ç‰¹ã«ã€{title}ã€ã®ã‚ˆã†ãªãƒ†ãƒ¼ãƒã¯ã€å¤šãã®æ–¹ãŒæ°—ã«ãªã‚‹è©±é¡Œã®ä¸€ã¤ã§ã™ã€‚",
            f"ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³æŠ€è¡“ã®é€²åŒ–ã«ä¼´ã„ã€{keyword}ã€é–¢é€£ã‚¢ãƒ—ãƒªã®æ´»ç”¨åº¦ã‚‚ã¾ã™ã¾ã™é«˜ã¾ã£ã¦ã„ã¾ã™ã€‚",
            f"èª°ã‚‚ãŒåˆ©ç”¨ã™ã‚‹ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’é€šã˜ã¦ã€{keyword}ã€ã‚’ã‚ˆã‚Šä¾¿åˆ©ã«æ¥½ã—ã‚ã¾ã™ã€‚"
        ],
        [
            f"å¤šæ§˜ãªã‚¢ãƒ—ãƒªãŒç™»å ´ã—ã€{keyword}ã€ã‚¢ãƒ—ãƒªã®é¸æŠè‚¢ã‚‚åºƒãŒã£ã¦ã„ã¾ã™ã€‚",
            f"ã€{title}ã€ã‚’æ¢ã™æ–¹ãŒå¢—ãˆã‚‹ã»ã©æ³¨ç›®åº¦ã‚‚é«˜ã¾ã£ã¦ã„ã¾ã™ã€‚",
            f"ç”Ÿæ´»ã€å­¦ç¿’ã€è¶£å‘³ã€ãã—ã¦ã€{keyword}ã€ã¾ã§ã‚‚ã‚¢ãƒ—ãƒªã§ç°¡å˜ã«æ¥½ã—ã‚ã¾ã™ã€‚",
            f"ã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒªã¯æ™‚é–“ã‚’ç¯€ç´„ã—ã€åŠ¹ç‡çš„ãªãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚",
            f"ã€{keyword}ã€ã‚¢ãƒ—ãƒªã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ–°ã—ã„ä½“é¨“ã¨åˆ©ä¾¿æ€§ã‚’åŒæ™‚ã«æä¾›ã—ã¾ã™ã€‚",
            f"æ¯æ—¥ã®ã‚ˆã†ã«æ–°ã—ã„ã€{keyword}ã€ã‚¢ãƒ—ãƒªãŒç™»å ´ã—ã€é¸ã¶æ¥½ã—ã•ã‚‚å¢—ãˆã¦ã„ã¾ã™ã€‚"
        ],
        [
            f"ä¾‹ãˆã°ä»•äº‹åŠ¹ç‡ã‚’é«˜ã‚ã‚‹ã‚¢ãƒ—ãƒªã‹ã‚‰ã€{keyword}ã€ã‚’æ¥½ã—ã‚ã‚‹ã‚¨ãƒ³ã‚¿ãƒ¡ç³»ã¾ã§ç¨®é¡ã¯è±Šå¯Œã§ã™ã€‚",
            f"ã€{title}ã€ã¯å¤šãã®äººã«äººæ°—ã®ã‚«ãƒ†ã‚´ãƒªã®ä¸€ã¤ã§ã™ã€‚",
            f"ã‚²ãƒ¼ãƒ ã‚„ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã¨ä¸¦ã³ã€{keyword}ã€ã‚¢ãƒ—ãƒªã¯ä½™æš‡ã‚’è±Šã‹ã«ã—ã¦ãã‚Œã¾ã™ã€‚",
            f"ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã€é‡‘èã€äº¤é€šã¨åŒã˜ãã€{keyword}ã€ã‚¢ãƒ—ãƒªã‚‚ç”Ÿæ´»ã«æ¬ ã‹ã›ãªã„å­˜åœ¨ã§ã™ã€‚",
            f"å†™çœŸã‚„å‹•ç”»ã¨ä¸€ç·’ã«ã€{keyword}ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç®¡ç†ã§ãã‚‹ã‚¢ãƒ—ãƒªã‚‚å¤šãã‚ã‚Šã¾ã™ã€‚",
            f"ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒªã«è² ã‘ãªã„ãã‚‰ã„ã€{keyword}ã€ã‚¢ãƒ—ãƒªã‚‚æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚"
        ],
        [
            f"ã“ã®ã‚ˆã†ã«ã€{keyword}ã€ã‚¢ãƒ—ãƒªã¯å˜ãªã‚‹æ©Ÿèƒ½ã‚’è¶…ãˆã€ç”Ÿæ´»å…¨èˆ¬ã‚’å¤‰ãˆã‚‹åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚",
            f"ã€{title}ã€ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€æš®ã‚‰ã—ã®è³ªãŒã•ã‚‰ã«å‘ä¸Šã™ã‚‹ã§ã—ã‚‡ã†ã€‚",
            f"å¿…è¦ãªã¨ãã«ã€{keyword}ã€ã‚¢ãƒ—ãƒªã§æ¬²ã—ã„æ©Ÿèƒ½ã‚’ã™ãã«åˆ©ç”¨ã§ãã¾ã™ã€‚",
            f"ä¾¿åˆ©ã•ã ã‘ã§ãªãã€{keyword}ã€ã‚¢ãƒ—ãƒªã¯æ–°ã—ã„ä½“é¨“ã‚‚æä¾›ã—ã¦ãã‚Œã¾ã™ã€‚",
            f"å¤šãã®äººãŒã€{keyword}ã€ã‚¢ãƒ—ãƒªã®ãŠã‹ã’ã§ã‚ˆã‚Šã‚¹ãƒãƒ¼ãƒˆãªç”Ÿæ´»ã‚’æ¥½ã—ã‚“ã§ã„ã¾ã™ã€‚",
            f"ã€{keyword}ã€ã‚¢ãƒ—ãƒªä¸€ã¤ãŒç”Ÿæ´»ã‚¹ã‚¿ã‚¤ãƒ«å…¨ä½“ã‚’å¤‰ãˆã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚"
        ]
    ]

    intro_sentences = []
    for group in intro_groups:
        intro_sentences.extend(random.sample(group, k=random.choice([1, 2])))

    intro_text = " ".join(intro_sentences)

    first = f'''
<div id="jm">&nbsp;</div>
<p data-ke-size="size18">{intro_text}</p>
<span><!--more--></span>
<p data-ke-size="size18">&nbsp;</p>
'''
    return first

# =============== ë§ˆë¬´ë¦¬ ë¸”ë¡ ===============
def build_ending_block(title: str, keyword: str) -> str:
    end_groups = [
        [
            f"ä»Šå›ã”ç´¹ä»‹ã—ãŸã€{title}ã€é–¢é€£ã‚¢ãƒ—ãƒªãŒçš†ã•ã‚“ã®ã‚¹ãƒãƒ›ãƒ©ã‚¤ãƒ•ã«å½¹ç«‹ã¦ã°å¹¸ã„ã§ã™ã€‚",
            f"æœ¬è¨˜äº‹ã§ã¾ã¨ã‚ãŸã€{title}ã€ã‚¢ãƒ—ãƒªãŒæ—¥å¸¸ç”Ÿæ´»ã§ä¾¿åˆ©ã«æ´»ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚",
            f"ä»Šå›å–ã‚Šä¸Šã’ãŸã€{title}ã€é–¢é€£ã‚¢ãƒ—ãƒªãŒã‚¹ãƒãƒ¼ãƒˆãªé¸æŠã«å½¹ç«‹ã¤ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚",
            f"æœ¬è¨˜äº‹ã§ç´¹ä»‹ã—ãŸã€{title}ã€ã‚¢ãƒ—ãƒªãŒçš†æ§˜ã®ç”Ÿæ´»ã«æ¬ ã‹ã›ãªã„ãƒ„ãƒ¼ãƒ«ã¨ãªã‚Œã°å¬‰ã—ã„ã§ã™ã€‚",
            f"ã€{title}ã€ã«é–¢å¿ƒã®ã‚ã‚‹æ–¹ã«ã¨ã£ã¦ä»Šå›ã®ã¾ã¨ã‚ãŒæœ‰æ„ç¾©ãªæ™‚é–“ã¨ãªã‚Œã°å¹¸ã„ã§ã™ã€‚",
            f"ã•ã¾ã–ã¾ãªã€{keyword}ã€ã‚¢ãƒ—ãƒªã‚’è¦‹ã¦ããŸã“ã¨ã§ã€ã‚¹ãƒãƒ›æ´»ç”¨ãŒã•ã‚‰ã«è±Šã‹ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚"
        ],
        [
            f"å„ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ã‚„ç‰¹å¾´ã‚’ã—ã£ã‹ã‚Šè§£èª¬ã—ã¾ã—ãŸã®ã§ã€{keyword}ã€ã‚¢ãƒ—ãƒªé¸ã³ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚",
            f"ã‚¢ãƒ—ãƒªã®ç‰¹å¾´ã‚„é•·æ‰€ãƒ»çŸ­æ‰€ã‚’æ¯”è¼ƒã—ã¾ã—ãŸã®ã§ã€{title}ã€é¸ã³ã«ãã£ã¨å½¹ç«‹ã¤ã¯ãšã§ã™ã€‚",
            f"ä»Šå›ã®ã¾ã¨ã‚ã‚’ã‚‚ã¨ã«ã€è‡ªåˆ†ã«åˆã£ãŸã€{keyword}ã€ã‚¢ãƒ—ãƒªã‚’è¦‹ã¤ã‘ã¦ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚",
            f"å¿…è¦ãªã¨ãã«ã™ãä½¿ãˆã‚‹ã‚ˆã†ã€é‡è¦ãªæƒ…å ±ã‚’æ•´ç†ã—ã¾ã—ãŸã®ã§ãœã²å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚",
            f"ã“ã‚Œã‹ã‚‰ã€{keyword}ã€ã‚¢ãƒ—ãƒªã‚’é¸ã¶éš›ã«æœ¬è¨˜äº‹ãŒå¿ƒå¼·ã„ã‚¬ã‚¤ãƒ‰ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚",
            f"è¤‡æ•°ã®ã‚¢ãƒ—ãƒªã‚’æ¯”è¼ƒã—ãŸã“ã¨ã§ã€ã‚ˆã‚Šè³¢ã„é¸æŠã«è¿‘ã¥ã‘ãŸã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚"
        ],
        [
            "ä»Šå¾Œã‚‚ã•ã¾ã–ã¾ãªã‚¢ãƒ—ãƒªæƒ…å ±ã‚’æº–å‚™ã—ã¦ãŠå±Šã‘ã—ã¾ã™ã€‚",
            f"ã“ã‚Œã‹ã‚‰ã‚‚ã€{keyword}ã€ã«é–¢ã™ã‚‹å½¹ç«‹ã¤æƒ…å ±ã‚„ãŠã™ã™ã‚ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ã„ãã¾ã™ã€‚",
            "èª­è€…ã®çš†æ§˜ã®ã”æ„è¦‹ã‚’åæ˜ ã—ã€ã‚ˆã‚Šæœ‰ç›Šãªè¨˜äº‹ã‚’ãŠå±Šã‘ã§ãã‚‹ã‚ˆã†åŠªã‚ã¾ã™ã€‚",
            "å¼•ãç¶šãæ–°ã—ã„ã‚¢ãƒ—ãƒªã‚„æ³¨ç›®ã®æ©Ÿèƒ½ã‚’ç´¹ä»‹ã—ã¦ã„ãäºˆå®šã§ã™ã€‚",
            "ã“ã‚Œã‹ã‚‰ã‚‚å¿…è¦ã¨ã•ã‚Œã‚‹å®Ÿç”¨çš„ãªæƒ…å ±ã‚’ç¶™ç¶šçš„ã«ç™ºä¿¡ã—ã¦ã„ãã¾ã™ã€‚",
            f"ã€{title}ã€ã®ã‚ˆã†ã«æ³¨ç›®ã•ã‚Œã‚‹ãƒ†ãƒ¼ãƒã‚’ã“ã‚Œã‹ã‚‰ã‚‚ç©æ¥µçš„ã«æ‰±ã£ã¦ã„ãã¾ã™ã€‚"
        ],
        [
            "ã‚³ãƒ¡ãƒ³ãƒˆã‚„ã„ã„ã­ã¯å¤§ããªåŠ±ã¿ã«ãªã‚Šã¾ã™ã€‚æ°—è»½ã«å‚åŠ ã—ã¦ã„ãŸã ã‘ã‚‹ã¨å¬‰ã—ã„ã§ã™ã€‚",
            "ã”è³ªå•ã‚„ã”æ„è¦‹ãŒã‚ã‚Œã°ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç©æ¥µçš„ã«åæ˜ ã—ã¦ã„ãã¾ã™ã€‚",
            "çš†æ§˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã‚ˆã‚Šè‰¯ã„è¨˜äº‹ä½œã‚Šã«æ¬ ã‹ã›ãªã„åŠ›ã¨ãªã‚Šã¾ã™ã€‚",
            "ã„ã„ã­ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã§å¿œæ´ã—ã¦ã„ãŸã ã‘ã‚Œã°ã€ã•ã‚‰ã«å……å®Ÿã—ãŸæƒ…å ±ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚",
            "æ°—ã«ãªã‚‹ã‚¢ãƒ—ãƒªã‚„æ©Ÿèƒ½ãŒã‚ã‚Œã°ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã§æ•™ãˆã¦ãã ã•ã„ã€‚å‚è€ƒã«ã—ã¦å–ã‚Šä¸Šã’ã¾ã™ã€‚",
            f"ã€{keyword}ã€ã‚¢ãƒ—ãƒªã«é–¢ã™ã‚‹çš†æ§˜ã®è€ƒãˆã‚‚ã€ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã§è‡ªç”±ã«å…±æœ‰ã—ã¦ãã ã•ã„ã€‚"
        ]
    ]

    end_sentences = []
    for group in end_groups:
        end_sentences.extend(random.sample(group, k=random.choice([1, 2])))

    end_text = " ".join(end_sentences)

    last = f"""
<p data-ke-size="size18">&nbsp;</p>
<div style="margin:40px 0px 20px 0px;">
<p data-ke-size="size18">{end_text}</p>
<p data-ke-size="size18">&nbsp;</p>
</div>
"""
    return last
# ================================
# ê´€ë ¨ ì¶”ì²œê¸€ ë°•ìŠ¤ (RSS ëœë¤ 4ê°œ)
# ================================
def get_related_posts(blog_id, count=4):
    import feedparser, random
    rss_url = f"https://www.blogger.com/feeds/{blog_id}/posts/default?alt=rss"
    feed = feedparser.parse(rss_url)

    if not feed.entries:
        return ""

    # ëœë¤ìœ¼ë¡œ countê°œ ì¶”ì¶œ
    entries = random.sample(feed.entries, min(count, len(feed.entries)))

    # HTML ë°•ìŠ¤ ìƒì„±
    html_box = """
<div style="background: rgb(239, 237, 233); border-radius: 8px; border: 2px dashed rgb(167, 162, 151); 
            box-shadow: rgb(239, 237, 233) 0px 0px 0px 10px; color: #565656; font-weight: bold; 
            margin: 2em 10px; padding: 2em;">
  <p data-ke-size="size16" 
     style="border-bottom: 1px solid rgb(85, 85, 85); color: #555555; font-size: 16px; 
            margin-bottom: 15px; padding-bottom: 5px;">â™¡â™¥ é–¢é€£ãŠã™ã™ã‚è¨˜äº‹</p>
"""

    for entry in entries:
        title = entry.title
        link = entry.link
        html_box += f'<a href="{link}" style="color: #555555; font-weight: normal;">â— {title}</a><br>\n'

    html_box += "</div>\n"
    return html_box


# =============== ëŒ€ìƒ í–‰/í‚¤ì›Œë“œ/ë¼ë²¨ ì„ íƒ ===============
def pick_target_row(ws):
    rows = ws.get_all_values()
    for i, row in enumerate(rows[1:], start=2):  # 2í–‰ë¶€í„°
        a = row[0].strip() if len(row) > 0 and row[0] else ""  # Aì—´ = í‚¤ì›Œë“œ
        d = row[3].strip() if len(row) > 3 and row[3] else ""  # Dì—´ = ì™„ë£Œ
        if a and d != "å®Œ":  # ì¼ë³¸ ë²„ì „ì—ì„œëŠ” ì™„ë£Œ í‘œì‹œë¥¼ 'å®Œ'ìœ¼ë¡œ ê¸°ë¡
            return i, row
    return None, None


# =============== Hì—´ ë¡œê·¸ ëˆ„ì  ===============
def sheet_append_log(ws, row_idx, message, tries=3, delay=2):
    """Hì—´(8ì—´)ì— íƒ€ì„ìŠ¤íƒ¬í”„+ë©”ì‹œì§€ë¥¼ ì´ì–´ ë¶™ì—¬ ê¸°ë¡"""
    ts = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()) + "Z"
    line = f"[{ts}] {message}"
    for t in range(1, tries+1):
        try:
            prev = ws.cell(row_idx, 8).value or ""   # Hì—´
            new_val = (prev + (";" if prev else "") + line)
            ws.update_cell(row_idx, 8, new_val)
            print(f"[LOG:H{row_idx}] {line}")
            return True
        except Exception as e:
            print(f"[WARN] ë¡œê·¸ê¸°ë¡ ì¬ì‹œë„ {t}/{tries}: {e}")
            time.sleep(delay * t)
    print(f"[FAIL] ë¡œê·¸ê¸°ë¡ ì‹¤íŒ¨: {line}")
    return False


# =============== ë©”ì¸ ì‹¤í–‰ ===============
if __name__ == "__main__":
    try:
        # 1) sheet4ì—ì„œ ëŒ€ìƒ í–‰/ë°ì´í„°
        target_row, row = pick_target_row(ws4)
        if not target_row or not row:
            sheet_append_log(ws4, 2, "å‡¦ç†ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“(Aåˆ—)")
            raise SystemExit(0)

        keyword = row[0].strip()  # Aì—´ = í‚¤ì›Œë“œ
        label_val = row[1].strip() if len(row) > 1 else ""  # Bì—´ = ë¼ë²¨

        sheet_append_log(ws4, target_row, f"å¯¾è±¡è¡Œ={target_row}, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰='{keyword}', ãƒ©ãƒ™ãƒ«='{label_val}'")

        # 2) ì œëª© ìƒì„±
        title = make_post_title(keyword)
        sheet_append_log(ws4, target_row, f"ã‚¿ã‚¤ãƒˆãƒ«='{title}'")

        # 3) ì¸ë„¤ì¼ ìƒì„± & ì—…ë¡œë“œ
        thumb_dir = "thumbnails"
        os.makedirs(thumb_dir, exist_ok=True)
        thumb_path = os.path.join(thumb_dir, f"{keyword}.png")
        sheet_append_log(ws4, target_row, "ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆé–‹å§‹")
        thumb_url = make_thumb_with_logging(ws4, target_row, thumb_path, title)
        sheet_append_log(ws4, target_row, f"ã‚µãƒ ãƒã‚¤ãƒ«çµæœ: {thumb_url or 'å¤±æ•—'}")

        # 4) ì•± ID ëª©ë¡ ê²€ìƒ‰
        sheet_append_log(ws4, target_row, "ã‚¢ãƒ—ãƒªIDæ¤œç´¢é–‹å§‹")
        apps = search_app_store_ids(keyword, limit=10)
        if not apps:
            sheet_append_log(ws4, target_row, "ã‚¢ãƒ—ãƒªIDãªã— â†’ çµ‚äº†")
            # ğŸ‘‰ ì™„ë£Œ í‘œì‹œ í›„ ì¢…ë£Œ
            ws4.update_cell(target_row, 4, "å®Œ")      # Dì—´ ì™„ë£Œ
            ws4.update_cell(target_row, 7, "")        # Gì—´ = URL ë¹„ì›€
            sheet_append_log(ws4, target_row, "ã‚·ãƒ¼ãƒˆè¨˜éŒ²å®Œäº†: D='å®Œ', G='' (æ¤œç´¢çµæœãªã—)")
            raise SystemExit(0)

        sheet_append_log(ws4, target_row, f"ã‚¢ãƒ—ãƒªID={[(a['id'], a['name']) for a in apps]}")

        # 5) ì„œë¡ 
        html_full = build_css_block()
        html_full += build_intro_block(title, keyword)
        # âœ… ëª©ì°¨ ë¸”ë¡ ì¶”ê°€
        html_full += """
        <div class="mbtTOC"><button> ç›®æ¬¡ </button>
        <ul data-ke-list-type="disc" id="mbtTOC" style="list-style-type: disc;"></ul>
        </div>
        <p>&nbsp;</p>
        """
        sheet_append_log(ws4, target_row, "ã‚¤ãƒ³ãƒˆãƒ­ç”Ÿæˆå®Œäº†")

        # 6) ì¸ë„¤ì¼ ë³¸ë¬¸ ì‚½ì…
        if thumb_url:
            html_full += f"""
<p style="text-align:center;">
  <img src="{thumb_url}" alt="{keyword} ã‚µãƒ ãƒã‚¤ãƒ«" style="max-width:100%; height:auto; border-radius:10px;">
</p><br /><br />
"""
            sheet_append_log(ws4, target_row, "æœ¬æ–‡ã«ã‚µãƒ ãƒã‚¤ãƒ«æŒ¿å…¥")
        else:
            sheet_append_log(ws4, target_row, "ã‚µãƒ ãƒã‚¤ãƒ«ãªã—")

        # 7) í•´ì‹œíƒœê·¸
        tag_items = title.split()
        tag_str = " ".join([f"#{t}" for t in tag_items]) + " #AppStore"
        sheet_append_log(ws4, target_row, f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°='{tag_str}'")

        # 8) ì•± ìƒì„¸ ìˆ˜ì§‘ â†’ ë³¸ë¬¸ ì¡°ë¦½
        for j, app in enumerate(apps, 1):
            if j > 7:  # ì¼ë³¸ ë²„ì „ì€ 7ê°œê¹Œì§€
                break
            try:
                sheet_append_log(ws4, target_row, f"[{j}] ã‚¢ãƒ—ãƒªåé›†é–‹å§‹ id={app['id']}")
                detail = fetch_app_detail(app["id"])
                app_url = detail["url"]
                app_name = detail["name"]
                src_html = detail["desc_html"]
                images = detail["images"]

                desc_html = rewrite_app_description(src_html, app_name, keyword)
                sheet_append_log(ws4, target_row, f"[{j}] {app_name} èª¬æ˜ãƒªãƒ©ã‚¤ãƒˆæˆåŠŸ")

                img_group_html = "".join(
                    f'<div class="img-wrap"><img src="{img_url}" alt="{app_name}_{cc}"></div>'
                    for cc, img_url in enumerate(images, 1)
                )

                section_html = f"""
                <h2 data-ke-size="size26">{j}. {app_name} ã‚¢ãƒ—ãƒªç´¹ä»‹</h2>
                <br />
                {desc_html}
                <p data-ke-size="size18"><b>2) {app_name} ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ</b></p>
                <div class="img-group">{img_group_html}</div>
                <br />
                <p data-ke-size="size18" style="text-align:center;">
                  <a href="{app_url}" class="myButton">{app_name} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>
                </p>
                <br />
                <p data-ke-size="size18">{tag_str}</p>
                <br /><br />
                """
                # âœ… 3ë²ˆì§¸ ì„¹ì…˜ì´ë©´ ë¼ë²¨ ê¸°ë°˜ ì¶”ì²œ ë°•ìŠ¤ ì‚½ì…
                if j == 2 and label_val:
                    encoded_label = urllib.parse.quote(label_val)
                    section_html += f"""
                <div class="ottistMultiRelated">
                  <a class="extL alt" href="{BLOG_URL}search/label/{encoded_label}?&max-results=10">
                    <span style="font-size: medium;"><strong>ãŠã™ã™ã‚ {label_val} ã‚¢ãƒ—ãƒªã‚’è¦‹ã‚‹</strong></span>
                    <i class="fas fa-link 2xs"></i>
                  </a>
                </div>
                <br /><br /><br />
                """
                
                html_full += section_html
                sheet_append_log(ws4, target_row, f"[{j}] {app_name} ã‚»ã‚¯ã‚·ãƒ§ãƒ³å®Œäº†")
            except Exception as e_each:
                sheet_append_log(ws4, target_row, f"[{j}] ã‚¢ãƒ—ãƒªå‡¦ç†å¤±æ•—: {e_each}")

        # 9) ë§ˆë¬´ë¦¬
        html_full += build_ending_block(title, keyword)
        sheet_append_log(ws4, target_row, "ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆå®Œäº†")
        related_box = get_related_posts(BLOG_ID, count=4)
        html_full += related_box
        # âœ… ìë™ ëª©ì°¨ ìŠ¤í¬ë¦½íŠ¸ í˜¸ì¶œ
        html_full += "<script>mbtTOC();</script>"

        # 10) ì—…ë¡œë“œ
        try:
            labels = make_post_labels(row)  # ["ã‚¢ãƒ—ãƒª", Bì—´ ê°’]
            post_body = {"content": html_full, "title": title, "labels": labels}
            res = blog_handler.posts().insert(blogId=BLOG_ID, body=post_body,
                                              isDraft=False, fetchImages=True).execute()
            post_url = res.get("url", "")
            sheet_append_log(ws4, target_row, f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {post_url}")
        except Exception as up_e:
            sheet_append_log(ws4, target_row, f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {up_e}")
            raise

        # 11) ì‹œíŠ¸ ê¸°ë¡
        ws4.update_cell(target_row, 4, "å®Œ")      # Dì—´ ì™„ë£Œ
        ws4.update_cell(target_row, 7, post_url)  # Gì—´ = URL
        sheet_append_log(ws4, target_row, f"ã‚·ãƒ¼ãƒˆè¨˜éŒ²å®Œäº†: D='å®Œ', G='{post_url}'")

        # 12) ì™„ë£Œ
        sheet_append_log(ws4, target_row, "æ­£å¸¸çµ‚äº†")

    except SystemExit:
        pass
    except Exception as e:
        tb = traceback.format_exc()
        row_for_err = target_row if 'target_row' in locals() and target_row else 2
        sheet_append_log(ws4, row_for_err, f"å¤±æ•—: {e}")
        sheet_append_log(ws4, row_for_err, f"Trace: {tb.splitlines()[-1]}")
        print("å¤±æ•—:", e, tb)












