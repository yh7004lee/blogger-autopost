from oauth2client.service_account import ServiceAccountCredentials
import httplib2
import json
import time
import advertools as adv

# âœ… ì—¬ëŸ¬ ê°œ ë¸”ë¡œê·¸ sitemap ë¦¬ìŠ¤íŠ¸
sitemaps = [
    "https://movie.appsos.kr/sitemap.xml",
    "https://jpapp.appsos.kr/sitemap.xml",
    "https://apk.appsos.kr/sitemap.xml",
    "https://appbr.appsos.kr/sitemap.xml",
    "https://appid.appsos.kr/sitemap.xml",
    "https://apptk.appsos.kr/sitemap.xml",
    "https://japan.appsos.kr/sitemap.xml",
    "https://cinebr.appsos.kr/sitemap.xml",
    "https://cineindo.appsos.kr/sitemap.xml",
    "https://cinetrk.appsos.kr/sitemap.xml",

    # í•„ìš”í•œ ë§Œí¼ ì¶”ê°€
]

JSON_KEY_FILE = "D:/py/geometric-shift-369100-21ba5abf1bac.json"  # ì„œë¹„ìŠ¤ê³„ì • í‚¤
SCOPES = ["https://www.googleapis.com/auth/indexing"]
ENDPOINT = "https://indexing.googleapis.com/v3/urlNotifications:publish"

# âœ… êµ¬ê¸€ ì¸ì¦
credentials = ServiceAccountCredentials.from_json_keyfile_name(JSON_KEY_FILE, scopes=SCOPES)
http = credentials.authorize(httplib2.Http())

# âœ… í†µê³„ ë³€ìˆ˜
total_urls = 0
success_count = 0
fail_count = 0
fail_list = []

for sitemap in sitemaps:
    try:
        # ì‚¬ì´íŠ¸ë§µ ë¶ˆëŸ¬ì˜¤ê¸°
        sitemap_urls = adv.sitemap_to_df(sitemap)
        url_lists = sitemap_urls["loc"].to_list()

        # ìµœì‹  5ê°œë§Œ
        latest_urls = url_lists[:5]

        print(f"\nğŸ“Œ {sitemap} â†’ {len(latest_urls)}ê°œ ìƒ‰ì¸ ìš”ì²­ ì‹œì‘")

        for url in latest_urls:
            total_urls += 1
            content = {
                "url": url,
                "type": "URL_UPDATED"
            }
            json_content = json.dumps(content)

            try:
                response, content = http.request(
                    ENDPOINT,
                    method="POST",
                    body=json_content
                )
                result = json.loads(content.decode())

                # ì„±ê³µ/ì‹¤íŒ¨ íŒë³„
                if response.status == 200:
                    success_count += 1
                    print(f"âœ… ì„±ê³µ: {url}")
                else:
                    fail_count += 1
                    fail_list.append(url)
                    print(f"âŒ ì‹¤íŒ¨: {url} â†’ {result}")

            except Exception as e:
                fail_count += 1
                fail_list.append(url)
                print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {url} â†’ {e}")

            time.sleep(0.2)  # ìš”ì²­ ê°„ê²© (0.2ì´ˆ ì˜ˆì‹œ)

    except Exception as e:
        print(f"âš ï¸ ì‚¬ì´íŠ¸ë§µ ì˜¤ë¥˜: {sitemap} â†’ {e}")

# âœ… ìµœì¢… ê²°ê³¼ ìš”ì•½
print("\n================ ìµœì¢… ì‹¤í–‰ ê²°ê³¼ ================")
print(f"ì´ ìš”ì²­ URL: {total_urls}ê°œ")
print(f"ì„±ê³µ: {success_count}ê°œ")
print(f"ì‹¤íŒ¨: {fail_count}ê°œ")

if fail_list:
    print("\nâŒ ì‹¤íŒ¨í•œ URL ëª©ë¡:")
    for u in fail_list:
        print("-", u)
print("================================================")
